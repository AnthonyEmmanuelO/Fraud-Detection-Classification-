{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fraud Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification is one of the most widely used techniques in machine learning, with a broad array of\n",
    "applications, including sentiment analysis, ad targeting, spam detection, risk assessment, medical\n",
    "diagnosis and image classification. The core goal of classification is to predict a category or class y from\n",
    "some inputs x. As part of this project I'll be analyzing the fraud cases on a arbitary dataset and build multiple models based on the evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df= pd.read_csv('fraud_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the data consist of predictor variables which are already normalized and pre-processed for consumption we will be removing the pre-processing steps to the model building process. In this section, we define our features and target variable and then we split our data set into train and test sets. Our features inclues v1,...v28 as well as time since the customer has last visited the platform or product. Our target is class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing the distribution of the class we see there is vast difference in the counts of customer fraud and customers who are not fraud. This kind of distribution is quite common in such scenarios wherein we are targetiing towards predicting a class which occurs rarely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fraud</th>\n",
       "      <th>Not Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>492</td>\n",
       "      <td>284315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fraud  Not Fraud\n",
       "1    492     284315"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bincount = np.bincount(y)\n",
    "pd.DataFrame({'Not Fraud':bincount[0],'Fraud':bincount[1]},index=[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the distribution of class is not even, we will be defining a stratified samples with equal distribution of class using scikit learn which will give us equal percentage of each class in our test and training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets tune our mode to find the best parameters i.e. the nmber of nearest neighbors for or knn model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  42 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=8)]: Done  60 out of  60 | elapsed:  4.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 2}\n",
      "precision\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  42 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=8)]: Done  60 out of  60 | elapsed:  4.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 10}\n",
      "recall\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  42 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=8)]: Done  60 out of  60 | elapsed:  4.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3,random_state= 1, shuffle= True)\n",
    "scores = ['accuracy', 'precision', 'recall']\n",
    "tuning_parameters = {'n_neighbors':np.arange(1,21)}\n",
    "dict = {}\n",
    "for score in scores:    \n",
    "    print(score)\n",
    "    clf = GridSearchCV(KNeighborsClassifier(), tuning_parameters, cv=skf,\n",
    "                           scoring=scores, refit=score, error_score =0, n_jobs=8, pre_dispatch = 8,verbose = True)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(clf.best_params_)\n",
    "    dict[score]=clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Score Comparison with different Parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on our tuning we found multiple parameter for best performance in respective scores. As we are targeting better predictions towards finding the fraud cases we will be looking at the recall scores to be higher. We will build our model based on the best parameter suited towards finding the best recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  42 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=8)]: Done  60 out of  60 | elapsed:  4.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=1, shuffle=True),\n",
       "       error_score=0,\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid=True, n_jobs=8,\n",
       "       param_grid={'n_neighbors': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20])},\n",
       "       pre_dispatch=8, refit='recall', return_train_score='warn',\n",
       "       scoring=['accuracy', 'precision', 'recall'], verbose=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(KNeighborsClassifier(), tuning_parameters, cv=skf,\n",
    "                           scoring=scores, refit='recall', error_score =0, n_jobs=8, pre_dispatch = 8,verbose = True)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classifier\n",
      " [[71048    31]\n",
      " [   99    24]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "knn_predicted = clf.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, knn_predicted)\n",
    "\n",
    "print('KNN Classifier\\n', confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n",
      "Precision: 0.44\n",
      "Recall: 0.20\n",
      "F1: 0.27\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "# Accuracy = TP + TN / (TP + TN + FP + FN)\n",
    "# Precision = TP / (TP + FP)\n",
    "# Recall = TP / (TP + FN)  Also known as sensitivity, or True Positive Rate\n",
    "# F1 = 2 * Precision * Recall / (Precision + Recall) \n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(y_test, knn_predicted)))\n",
    "print('Precision: {:.2f}'.format(precision_score(y_test, knn_predicted)))\n",
    "print('Recall: {:.2f}'.format(recall_score(y_test, knn_predicted)))\n",
    "print('F1: {:.2f}'.format(f1_score(y_test, knn_predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      not 1       1.00      1.00      1.00     71079\n",
      "          1       0.44      0.20      0.27       123\n",
      "\n",
      "avg / total       1.00      1.00      1.00     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Combined report with all above metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, knn_predicted, target_names=['not 1', '1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression is a statistical method for analyzing a dataset in which there are one or more independent variables that determine an outcome. The outcome is measured with a dichotomous variable (in which there are only two possible outcomes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As there is 2 parameter to be tuned in the process we will be using regularization as the prameter tuning stage to find the optimal result for varied scoring measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  24 out of  24 | elapsed:   48.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'penalty': 'l1'}\n",
      "precision\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  24 out of  24 | elapsed:   44.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'penalty': 'l1'}\n",
      "recall\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  24 out of  24 | elapsed:   48.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'penalty': 'l1'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "dict_log={}\n",
    "tuning_params_log = {'penalty':['l1','l2'],'C':[1,10,50,100]}\n",
    "for score in scores:    \n",
    "    print(score)\n",
    "    clf = GridSearchCV(LogisticRegression(), tuning_params_log, cv=skf,\n",
    "                           scoring=scores, refit=score, error_score =0, n_jobs=8, pre_dispatch = 8,verbose = True)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(clf.best_params_)\n",
    "    dict_log[score]=clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': {'C': 10, 'penalty': 'l1'},\n",
       " 'precision': {'C': 1, 'penalty': 'l1'},\n",
       " 'recall': {'C': 10, 'penalty': 'l1'}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Score Comparison with different parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  24 out of  24 | elapsed:   47.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=1, shuffle=True),\n",
       "       error_score=0,\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=8,\n",
       "       param_grid={'C': [1, 10, 50, 100], 'penalty': ['l1', 'l2']},\n",
       "       pre_dispatch=8, refit='recall', return_train_score='warn',\n",
       "       scoring=['accuracy', 'precision', 'recall'], verbose=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuning_params_log = {'penalty':['l1','l2'],'C':[1,10,50,100]}\n",
    "\n",
    "clf = GridSearchCV(LogisticRegression(), tuning_params_log, cv=skf,\n",
    "                           scoring=scores, refit='recall', error_score =0, n_jobs=8, pre_dispatch = 8,verbose = True)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classifier\n",
      " [[71070     9]\n",
      " [   36    87]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "log_predicted = clf.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, log_predicted)\n",
    "\n",
    "print('Logistic Regression Classifier\\n', confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n",
      "Precision: 0.91\n",
      "Recall: 0.71\n",
      "F1: 0.79\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "# Accuracy = TP + TN / (TP + TN + FP + FN)\n",
    "# Precision = TP / (TP + FP)\n",
    "# Recall = TP / (TP + FN)  Also known as sensitivity, or True Positive Rate\n",
    "# F1 = 2 * Precision * Recall / (Precision + Recall) \n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(y_test, log_predicted)))\n",
    "print('Precision: {:.2f}'.format(precision_score(y_test, log_predicted)))\n",
    "print('Recall: {:.2f}'.format(recall_score(y_test, log_predicted)))\n",
    "print('F1: {:.2f}'.format(f1_score(y_test, log_predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      not 1       1.00      1.00      1.00     71079\n",
      "          1       0.91      0.71      0.79       123\n",
      "\n",
      "avg / total       1.00      1.00      1.00     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Combined report with all above metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, log_predicted, target_names=['not 1', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAF8CAYAAADVQCwpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21e5afe66d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAboAAAGPCAYAAAAqQBWbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAIABJREFUeJzs3XeYVOX1wPHvGfouVUFAioiNooIQFax0EBAboNhA0Bg1\n6A9jN1GwRE0iGhMUrKgkGIkaFVAEKQIWmhUVG8WCFGkqnT2/P947u7OzM7MzuzNzZ2bP53nm2d1b\nz5S9Z+573/dcUVWMMcaYXBXwOwBjjDEmlSzRGWOMyWmW6IwxxuQ0S3TGGGNymiU6Y4wxOc0SnTHG\nmJxmic4YY0xOs0RnjDEmp1miM8YYk9MyNtGJyCoRKQh77BSRb0XkfyLSL87ttBaRf4jIJyKyRUS2\ni8hKEfmXiPRJIJ6BIjJZRL4RkV9EZIeIrBGRV0XkMhGpWfZna0KJyDEisldE/h5h3mkicruIvCIi\n34d8Ng70KdY6IjLO+7zu8mKZHee6lUTkHBH5s4jMEJGN3vrb41y/lojcKyIrvM/jBu/zeGr5nlXU\nWAtEZHeEed8l8z0Qkbu87d2SjO2lSzbFLSIjvFgfjTL/Ju+YuT30fReR7t7fb6Qx1lO9fd5V1m1U\nTmZASabeYyHwlTetDnAMMAAYICJjVfW6aBvwXpgbcQn9B2A2sAtoDZwHDBGR6cAQVf05yjZaAv8F\n2nvxfAbM8LbTBOgB9APuFpGOqvpteZ60AeAfwHbgjgjz/g3UDpvmZx27x4CBwErgBWAn8Hmc69YF\nplCG+EWkIe5/oyXwPfAy0Ag4DegrIlep6vhEt1tGChQkeXslXhMR6Q7MBGapaq8k7i9ZIsadwaK9\nzlcDfwY2A9OBbcDe0tZLFVWdJyIzgGtF5HFVXVWWjWTkA3fg2AdcHDY9APwd94+1D+gYZf0HvGV+\nDd+GN/844AtvmbeByhGWaQas8/YzH2gbYZl84A/AJuBov1+3bH/gkkYBcE+U+Y/jvrz0APYP+Rwc\n6EOslYHd3mcsvwzr1wKeAf4POAX3Ja4A2B7HulO9ZacD1UKm98MdlHYDrZP4XCt5+9sdYd7BwOFA\nIEn72s/bXr2w6d29GN7w8zMaI+47vc/iLX7HEkestbzX+IAI8+Z7z+OUCPOqe+s1SXO8x3nv/XNl\nWt/vFzzGE4uY6Lx51YAt3vzREeb3DDkA9o+xj6bAT95yYyLMfyskEVYtJd6WQEO/X7dsf+DOUvYB\nh8W5vJ+Jrrm3/2+StL1D4kl0wFHecruAxhHmP+W9Jk8n8blGTXRpfL17WKJLy/NY7df/VClxfeR9\ngUs4yWbsNbpYVHUX8KX3Z8MIi9yCO7V+RVWnxtjOd7gPpwBXi0h+cJ6InAKc5G3nd6pa4tpE2La+\nUdV1iTwPEekgIk971/12iMhPIvKBiPxFRJqFLDfUa6N+Msp2DvLmfxNtuogERORaEVkmIj+LyD4R\nqe3td4+INI4R53+97YyMMG+giLwuIuu9a1TficizItI6kdfC21Z7oDPwjqp+WdryySYiR4jIU971\ntp3e+zFLRAZFWLYAWIX7fLSQ4teST0lxqGd5P99S1bUR5v8b95k+Q0QkkQ2LyIne+7nZ+5wsEpGh\npawT9RqdiNQXkX+Ku569U9z18bHeZ2+St975YeuUuNYlIvOBN3Cvd4+w1/uLkOWqiciNIrLEi3+X\niKwVkffEXc8Mb/Yu7fWo7F3PelPcNdBgP4E3ROSKOLdRRUQuEpF/i8jnIrLNu/b1mYg8ICKNoqxX\nR9z1249F5Ffvf/U7EZkvIqNFJBC2/LEiMsVbZpe4Pglfi8jzEtanQSJco/O2W4BryRIg+L4WvhdS\nyjU6EaknIneIO45t8+L+UERuFpEaEZYvfK/FHa+e8j4ru6Xk9cOnca0ovyv9VS8uk6/RlSb4gS2W\nXESkLnCy9+ezcWznWWCst70uwDRv+hnez49V9aNyRRqBiFwP3IP7QH0B/A+oARyKawr9BNeslZTd\nAS8CvXHNEp8CbVR1m4i8iLteeRHwlwhx7gf0x509TAqZXgl3QB2Euy61FHet6HDgfOBsETlLVRO5\naH0m7kD2ZqJPsLy8A8EUXGvBCtz1tgOAU4FuItJLVS8LWWUiUBPX1PoL7jouuPh/THG4x3j7WRJl\nfnB6LdxZ4ldRlitGRM7D/T8EcN+el+POWp/AnUVGE+1az4HAAqAFsBF41dv2UNxn8atI60XZ3jTc\n69wbd7099HP1o7c/AV7HvWdbgHnezwOAw4Drcf9Tn8Z4LqHx18U1DXfCff7f8fbdGGiHO148Esem\nDsQdpDfjrt9+gLvkcQxwDXCeiHRS1dUh+87z9tcKd4ybiWsib4TrY3AC7v91u7d8b9zrW8nb/gLc\n8b0JcLq32eCxLZppuBOIwbhj0ZTg9oEPS3uSInIk7vVvjHud3sKdGR4L3A2cJSLdVPWXkNWC73Ur\n4H1vf2/jPiebwnYxy/t5JvCn0uIpxu/T0RinqbGaLlsDe7z5HcLmdaWoOatpnPv62lv+9pBp87xp\nj6XguQ2g6PrhORHmtwKOCPl7qLf8k1G2dxARmtBCphfgmiMOibBu8LrH8ijbvtqb/5+w6Xd70xcC\nzcPmne29PxuB2gm8LsHXvE8C65S76RJ3IAw2hd8UNq8DRc3bI+J53csRR7xNlx948VwRY5lfvGV6\nxrnvA4GfvXWuDJvXA9hB9Gt030Z6D4BXvHVmEHINE9epbGHIe3d+2HoRmwAp5RpdyP/+u0D1CPM7\nAnUSeD9eDtlek7B5lQi7LBIj7tpAX6BShG3c4+3jpbB5lwSnE+HaJ+6abqWQv4NJZWCEZWsDx4ZN\nG+Ft/9F4389Y7wEuMQaP2X8Mi60G8Jy33vgIr1nwc/A4EfpKhCwbALZ6y5a4thjrkVVNl15zRy/c\nt+0AcKeqLgtbrEHI7/E2Ja6PsG6DsHnJNAb3LeYWVX0hfKaqfq6qK5K4PwVuVtWvI+zrTVwSbCUi\nx0dY9xJv/aeCE0SkHq4DxQ5col4Tts0XgQlAPeDCBOLs4P38LIF1kuG3uIPBElW9N3SG9/m6G3dW\nfH2a44qmlvfz1xjLBL81x9tUdxnuLGOBqj4cOkNVZ+EOQnETkYMp6hhzhaoWxqqqW4ErE9lenIKX\nMear6s7wmaq61Nt3qUSkA+5M6FdggKp+H7atfRrjskjYsttUdbqq7ouwjZtxx5i+IlI9wnOZpaol\nerSq6lth2zvA+/lalP0vjifWchiB++L3kqreFRqbqu4ALsV9YRwqkYdibQSuUdW9EeYFt1NAUY/m\nDtGWiyQbEt3EYDsx7lv367jmvQtVdbSvkZWBuG7h7fDO0NK46xdjzHsadyAfFjpRRNrhYl2L+1Ye\n1BX3LW2hqkZrppvnbfOEeILzmmqC10h/imedJDoVl8yjNRU/4f08LNr1lBwQfA3+FWX+0wlu7xTc\n+79YVb8Jn6mqH+KaRpNpKe7/6rci8jvvf62sgmNsX1XVpHzZFZF24q6TPyQiT3jXo57CvU6VcWf0\nQYu8nzeLyAVeM2osi7ztPCciJ3iXFtKpL+7z83ykmeqaK5cCVYHfRFjkjdAvQzEEjw0JvbfZcI1u\nAUXXGBrgrr/VBh4Rka8ifFPZGPJ7Q+C7OPYR/Da0IWTaBuCIkHnJ0tz7uVajjN1LgfWRvuGGeArX\n5n2uiPyfus4+AMNxH96n1Ws78LT0fvbwvoBEoxQ/S46l8B9Zi7fhl4uI7A/cT8lrPp+r6n3e7028\nnysjbUNVt4rIJtwZalPiuAYnImfhmqjDjVfV9+KJPYbg5yY/xjLBedvi3GZT72fE1yDG9NK2tyrG\nMquANgluNypV/VJErgXuA8YBD4vIKty1rleBF1R1T5ybOwj3mYl3TGRU4jq5/Rt3hhjpmqR40wvP\nvlV1toj8DRiFu26qXqebt3HNmdPC/idvAI7EJZx+wA4RWQrMBSap6hekVvCY8JyIPBdjuWjHhFVx\n7if4ea4X5/JAdiS6x1W18Ju2iNTCddzoCvxHRNqEHcTfp+jDdBylJDoRqY8bB6S4bxxBS3FJ9dhy\nP4PUK+3MfEesmaq6WkTm4F7Ts3Af1srAEG+RiVH29yXuWkss8R4otgR/EZGaSUx2NYGLKXmAmYc7\nIKZKB2+/4WYC5U10q3CdQ5pHmuk1LefjnvOqcu6rvCId2OOZV7adqT7kHWgH4HpNn4RXHAL4UkRO\nUtUNsbaRAn/FJblPgJtxx5aNwWY6EXkPd5ZTrIesqt4gIuO8dU8CTsS1ulwCvOt17NjpLfsj0EFc\nVZwe3rLHeevdIiI3qOrYFD7H4DFhOqVf7lkT9rdSyjEqRPDLwOY4lweyI9EVo6o/i8i5uAPoQcC1\nuFH8wfmbxXVFPgXXiSNWkx0UHYx+xn37CXoZdx3qKBFp5zW1JEPwTW4sIrXiPKsLDm2oFWX+QeUP\ni6eAbrh/ouCBoj7umk14V/9g9ZcVqjo8CftGVbeLyK9AHm4geFISnbqebKV9Efged/beMtJMcV3S\n98P9Q34faZkI+/0TifYMi98y3PsTqQmIkOk/E2ePS9zzOgTXQzKSaNNjba+09RLdZly8psbHvQci\n0gp3meB43LHisuhrF1qDSzytkhDSINxnZ1CUa++HRlvR+/z+03sgIsfimpePx/XOvjts+Xm4L3GI\nSDVcq8w/gXtF5L/h19OT6Fvc5+dRVX0lRfsAd2yA+PtfANlxja4EVd0I3IX7IF4nJcfGBBNffxE5\nnSjEjVW7Ffch/EfoWYT3gVno7eMREakSKyYROSSe6zfqxtp9iHvt400SwYNGtH+6/nFuJ5YXcD2a\nuolIUyJ0QgnxJi75dvHOiJMl2LEoac1ZcZqLe5+jjRcb4f38QiOPW0u3l7yfp0jk+pIXeD//F9a8\nFUvwmuoFUebHHEsXwXzv53Fex5RiROQooG2C2wx+4UvoC7qqfg78Dff82se52uvez9NFpLyXL4LN\nbCWSjDesJe5mOO9SzXjieC6quktVH8FdC61E7CEi5fWaF9PgVO1A3LjB4Pjc8E6IMWVlovM8jPvg\n1MF9symkbuzWQxRdnC3xT+r1MJyDuza0mMh1FS/EXfM7HpjjjRMJ305Nb0zcUuK/njfGi+1uETk7\nwjZbe99Cgxbh2qbbiMiFYcsOAkZSzmYgrwnkOdxn4kbceKXtRLi47H1j/geuWXBqlNelqoicLiKH\nJxDGHNzr0jnxZ1Auj+Fe3w4icnPoDBE5hqIvQ39Nc1wRqerHuDFPVYDHvW/uAIhIf9zndi+JNc0+\nhnu/T5awgdDiakxemmCMX+OasSrjviiGFmOoi/v/TVTwMsThEjZYOhiniPSJ0hEj+GVwVTw7UtWl\nuNc4H3jF+/IXuq9Ksb5Ehwk23xcruCCuqMI4Io9BPFtEToowvSquo0yxZmkRuU5EmkRYvg1FnVxW\nh89PovG4s7ohInJ36PsdEktjERlRctW4HY075nyacAehRMYipPNBjHF0IcsMw/Wy2gLUjTD/z7jx\nXAW4N+FFYDJuHFJw7MY0oFaMfbTEXffb563zCW5w8L9xY1d2etO/J85xe952b8IdjApwA1gn4649\nfuJNC6/xeU1IDAtxCehjbxujiT2OLq5xXhTVkws+Io7b85athLtIvs+LYSlugOlk3Lf54JisXgm8\nJu29/b4TY5k/4joXBB/BWJeGTBtXhs9bP1xX8n3e+/Ev3PW03UQZT5no6xtlvxNC4l4W8rkMfY43\nRlivIa7QwD5cAngOd2YafD8uL0Ms54f8v7yPKxAwz9ve30h8HF0Tiv6P13ufjxdwPec+xY2zKzH2\ni6KxVSVKaXmvUfA9egaXoO/25v3BW28zrtVhkre/1d70jcCRCbwe+3mv/z7c//mb3ufiTe/57I4n\nblxRgeD/7vu4Y0ewVeT1kH2cELLOP7zl13nLPIs7PgRr764EGoUs/7O3/HLvOU/CfXEMfn4fDYsp\nqePovHlHAt946/7kfR4n4VoglnvT18T7XkfY/vXesnck/Nku6z9oqh/eG7mX2IkugEsM+4If9gjL\ntMad3S3HNc1tx30T+heJDUweiDuIf4O7frTd+wd6GdfMV2KAahzbPM77IKzx/pE24P6R/0yEpIn7\npr4Yd0DejKsO0RV3wN0HfB22fMTppcT0EUUHyxJFXSMs3xt3AAs+h5+89+RfuGaMhF4XXC/bfYQM\nmA+b/5Q3P9bjzTJ+5o7AXctZHfJcZhJhEG5ZX98I25gfx/MpcTDy1q3lfVZWeJ/HDbjkcXI54jkR\nd2Ddgjt4LvY+38Fal7sirPOt93mJdGCsj7tGtAbX4WAlruB6bYoSc5ewdaLWjMSVp/oXLrkHD+Ir\nvHmHArd579lK7/9kAy653EGEuqBxvB6VgctxCX+T9xxW45rqLk0g7pO9uNZ5r+uHuAN3Je8zsJfi\nia69996+FfLa/Yhr3bmesC/2uCbnJ7ztbvA+D197n4cS9X5xiW4fMCHB97O7t96MKK9XTS++hbj/\nn53e9t71ns9x8b5mEbb9CWWsdSneBozJCCJyDi5x3q+qmTJA2ySZuNJyX+MOjPU1zoHcpmLyLjW9\ng6vQNKS05cNl8zU6k4PUVYpZCFwuIvGOwTMZSkQ6Rph2AG4Aeh1cJQ1LcqY0d+DODst0U1s7ozMZ\nR9xdDBYDj6jq1X7HY8rG6xSyB9d09Rmu6a8JrphxPq558WTNjJ6sJkN5YwNnA39WN2wn8W1YojPG\npIqI3IG7rtMS141+F0XXjh5U1S0xVjcmKXI20YnIybiLoh1xt404U0sZyCgiXXDlotriLgDfraqJ\n1vgzxhiTQXL5Gl0+bhjBlcQxxkxEWgBTcd1+2wF/x41R6hljnTxxN0/NS0bAxhjjh1w/luXsGV0o\nr/BwzDM6EbkPOE1Vjw6ZNhl3/6q+UdY5Addx4gKSUPzVGGN80go3bONEVX3b72CSLetqXaZQJ4ru\nYBs0AzfmJ5oW3s9otzYxxphs0gJ3h4ScYomuSCNKFgpdB9QWkWpadOuaUKsAJk2aROvWrRk1ahQP\nPBArL+Yee84Vgz3n3FFQACtWwPz5sGABLF8OrlPsheD/3S5SwhJd+ewEaN26NR06dKBOnTp06JDQ\njW+znj3nisGec3b7+WeYOROmTYPp0+HH6HdUjHXfyqxlia7Ij5S8a21DYFuUs7lCo0aNok6dOixa\ntIgBA9y9NocMGcKQIQkP4DfGmKT44guX2KZNg7fegj2Ft5yd7D1C5faYfUt0Rd4BTgub1subHtMD\nDzxAhw4dGDBgAK+8kspbMRljTGS7dsG8eUVnbV9FvRPhebj7SR9C8F6v1asvY+fOEkVsckbOJjrv\nNhGHUnTX3pYi0g7YpKrfisg9uKKlwVv4jAeu8npfPokb5DoQd2t6Y4zJON9/75LatGkwaxb8+mtp\nayiulvZb1K17PEOH9qZ/f6FmTeic7ptjpVHOJjrcXZbn4N5ZxQ0EB1djbziu80mz4MKqusq7CeID\nwNW46ugjVDW8J2ZUFbGp0p5zxWDPOTPs2weLFhU1SX7wQfzrVq6sNGs2l5Ur3wJgy5b3EIHu3Xvz\n/vspCjhDVIhxdKkiIh2ApUuXLs2Zi9bGmMyyeTPMmOES2+uvw8aN8a/buDH07Qt9+yqLFs3lvvve\nKrHMwoXDqV59Ax07dgToqKoJ3b07G+TyGZ0xxmQdVfjkk6Imybffdmdy8RCB4493ya1fPzjmGABl\n9OjISe7RR/tzwgnNWLZsQ1KfQ6axRGeMMT7bvh1mzy7qSLJmTfzr1q0LvXu7xNanDzQIubmVqkty\nd9wROclddlnudkAJZYnOGGN8sGpV0bW2OXNgZwIj2Nq2dYmtXz844QSoHOVIvnLlFv7yl5KFTipS\nkgNLdMYYkxZ79rhmyGBy+/TT+NetXh26dXOJrW9faNEivvVatqzH1KlD6N9/Mjt37gUqXpIDS3TG\nGJMyGzbAa6+5xDZjBmxNYFx28+ZFZ21du0JeGe8r0L17S6ZOHcKAAc/x4IO9K1ySA0t0xhiTNAUF\n8P77RdfaFi1ynUviUakSnHhi0Vlb27auc0kydO/ekq+/vppGjWomZ4NZxhKdMcaUQwJ1JEuoXx9O\nO80lt169oF691MVZUZMcWKIzxpiERa8jWbpjjilqkjz2WHcmZ1LLEp0xxpRi1y6X0ILJLXodyZLy\n86Fnz6ImyQMPTG5sqsrf//4eZ53VioMOqpvcjecIS3TGGBPB998XdSSZOTOeOpJFDj206KztlFOg\nWrXUxBg6Tu7vf3+PuXOHWrKLwBKdMcZQvjqSVarAqacWJbfDDktdnEHhg8FXrdpCly5PW7KLwBKd\nMabCSkYdyX79oEcPqFUrdXGGi1bxZNWqLSxYsMYSXRhLdMaYCkMVli8vOmtLtI7kcccVnbW1bw+B\nQGrjjaS0sl4XXHB0+oPKcJbojDE5bft2V2IrmNwSqSNZp05RHcnTTiteR9IPVruybCzRGWNyTrCO\n5PTprlhyWepI9u3r6khWqZKyMBO2Z08Bc+euLjHdklxsluiMMVnPjzqSfqhatRLTp59P377/5q23\nXMKzJFc6S3TGmKyUCXUk/ZCfX5Xp08+nf//JnH/+kZbk4mCJzhiTFVSL6khOm5Z4HckTTihKbsms\nI+mH/PyqzJp1EZUq+dAbJgtZojPGZKzQOpKvvQZr18a/7v77F9WR7N07tXUk/WBJLn6W6IwxGaW8\ndSSDY9uOO87qSBrHEp0xxlfJqiN52mnQpEnq4kyX4BCCBg3y+f3vj/M7nJxgic4Yk3Y//OC6/k+b\nBrNmwS+/xL9uuupI+iHSODlLduVnic4Yk3L79sHixUVnbe+/H/+6Vaq4hBZMbocfnro4/RQpyY0c\n+RqqysiRx/sYWfazRGeMSYlgHcnp011HkkTqSDZqVHStrWfP9NaR9EOsiifVq9thurzsFTTGJEWy\n6kj27es6lfhRR9IPVtYr9SzRGWPKLFl1JPv0gQMOSF2cmWzMmHmW5FLMEp0xJiGrVxcltkTrSLZp\nU3StLdPqSPqlRYu6iBQf/G5JLrks0RljYgrWkQz2kly+PP51q1d3JbaCyS2T60j6Zdiw9gAMH/4y\nqpbkUsESnTGmhPLUkWzWrCixdeuWXXUk/RJMdnv27LMklwKW6IwxVkcyAwSTnUk+S3TGVFA//+wG\nawfv22Z1JE2uskRnTAXyxRdF19rmzUusjmT79kVnbVZHMjGqyq5d+2xMnE/sVTcmh5W3jmSPHkVj\n23KhjqQfguPkXnvtK9544yLq1q3ud0gVjiU6Y3JMMupI9u0Lp56aW3Uk/RA+GLxXr2ct2fnAEp0x\nWc7qSGamSBVPFi/+gd69J7Fw4XAqV64gpV8ygCU6Y7LQli2u23/whqRlrSPZowfUrp26OCuqWGW9\nLr30GEtyaWaJzpgsEFpHcvp0WLgwsTqSxx5bdNZWkepI+sFqV2YeS3TGZKgdO1yJrWByW706/nVr\n1y6qI3naaRW3jqQf/vnPRZbkMowlOmMyiNWRzH4DB7bh4YeX8PnnRe3JluT8ZYnOGB/t3evqSAaT\nWyJ1JKtVcyW2gr0kDz44dXGa+DVuXIvZsy+mW7dn+PzzjZbkMoAlOmPSbMMGeP31ojqSW7bEv67V\nkcwOwWQ3b95qzjvvSL/DqfAs0RmTYuWpIxkIFK8jeeSRVkcyWzRuXMuSXIawRGdMCiSjjmTfvq5D\nyX77pS5OYyoCS3TGJMmXXxadtVkdydymqqxY8ROtWtX3OxQTB0t0xpTR7t3F60h++WX861odyewV\nHCd3zz0L+O9/BzNgwBF+h2RKYYnOmAQE60hOnw4zZyZWR/KQQ4rO2qyOZHYKHww+cODzluyygCU6\nY2IoTx3JypVL1pG0jiTZK1LFkz17Chg0aApffTWSZs3q+BidicXXRCciBwKXAicADYBpqnqbN+8Y\noDXwqqr+7F+UpqKxOpImXKyyXv/852mW5DKcb4lORAYBTwJ5gAAKfBiySAPgWWCY99OYlFCFTz8t\nOmuzOpImlNWuzH6+JDoR6QBMAvYBdwLzgDfDFnsT+Bk4HUt0Jsl27IA5c4qSm9WRNNHMnbvKklyW\n8+uM7iZv331V9U0ACbt4oar7ROQDoFwjLkXkKuA6oBHujHGkqi6OsfwFwPXAYcBW4DXgelXdVJ44\njP/KU0eydeuis7YTT7Q6khVJly4tuO22U4olO0ty2cWvRHcysCSY5GL4AWhX1p2IyLnA/cBvgUXA\nKGCGiByuqiWuvIjIicDTwDXAVKAJMAF4FBhY1jiMP8pbR7Jr16LkZnUkKy4RYfToLgDcccdbluSy\nkF+Jbj9cc2VpqnuPshoFTFDVZwBE5HdAP2A48JcIy3cCVqrqOO/v1SIyAbihHDGYNLI6kiYVgslu\nwIAj6NjxQL/DMQnyK9FtAprFsdwhwLqy7EBEqgAdgT8Hp6mqisgsoHOU1d4B7haR01T1NRFpCAwC\nppUlBpN6qvDBB0Vnbe+9Z3UkTWqIiCW5LOVXolsM9PaaEL+ItICIHAscBUwu4z7qA5UomSjXARFH\nd6rq2yJyIfAfEamOe31eAX5fxhhMCgTrSAYHbv/wQ/zr7ref60DSr5/VkTSmovAr0T0C9AemiMhA\nVS1WPElEWuCGHijuGllaiEgb4O/AaOANoDHwNy+GS6OtN2rUKOrUKT6OZsiQIQwZMiRlsVY0oXUk\n33rLld+KV7t2RWdtxx9vdSRNSarKc899wjnntKFq1dz+gEyePJnJk4ufP2zdutWnaNJDNN52nmTv\nWGQ8rpNIAfAR0B74Fvge1+RYBRinqiPLuP0qwHbgHFV9JWT6RKCOqp4VYZ1ngOqqOjhk2onAfKCx\nqq4LW74DsHTp0qV06NChLGGaKMpTRzIvr3gdyaZNUxenyX6h4+TOOOMInn9+UM4nu3DLli2jY8eO\nAB1VdZnf8SSbbwPGVfV3IrIC+CMuyYG7btcMN37uNlW9rxzb3yMiS4HuuOZHxI1h6A48FGW1PCD8\nXKEAd2ZpV29SbO1a1xQ5bVr56kiecgpUL08XJlNhhA8Gf/nlFQwePKVCJrtc5msJMFV9QETG4Xo7\ntgQCuLPJCOttAAAgAElEQVS6Baq6Iwm7GAtM9BJecHhBHjARQETuAQ5U1aHe8q8Cj3q9M2cABwIP\nAO+p6o9JiMeEKCgoXkdyWQLfI62OpCmvaBVPXn55BbNnr6RPn0N9iswkm+9FnVV1N/CW90j2tp8X\nkfrAHUBD4AOgt6pu8BZpREjvT1V9WkRqAlfhrs1twVVouSnZsVVUoXUkX3/dDQeIV8OGRXUke/a0\nOpKm7Eor62VJLrf4VQLsI+AlVb29lOVGA2epapkHjavqw8DDUeZdEmHaOGBchMVNGZSnjiQUryPZ\noYPVkTTlZ7UrKx6/zuiOBJbEsVwTylkCzKRfsupI9unjzuKMSaYNG7YzfvzSEtMtyeUu35suS1EN\nV/jZZLg1a4rXkdyRwBVWqyNp0umAA/KZPftiunV7hvXrfwUsyeW6TE90HYAE7gZm0sXqSJps1rbt\nAcyefTHduz/DnXd2tSSX49KW6ETklbBJ3SNMC6oMtAIOAqakNDATt40b3Y1Iy1JHsmnT4nUk8/NT\nF6cx8Wjb9gC++GIktWtX8zsUk2LpPKPrH/K7UjRmLpbPgJtTFpGJqbx1JDt3LkpuRx1l3f9N5rEk\nVzGkM9Gd7v0U3ADuWbhyW5HsBr5T1c/SEZgp8ssvro7ktGnlqyPZqxfsv3/q4jTGmHilLdGpauEd\nALwB3PNDpxn/BOtITp8O8+ZZHUmT/VSVe+9dQM+eh/Cb39gdByo6XzqjqOqxfuzXOFZH0uSy0HFy\n9923kFmzLrZkV8Fleq9LkyTlqSPZsmXRWdupp1odSZO5wgeDb926ix49nrFkV8H5muhEpB7ujt9H\nALWJXDhZVfWatAaWA8pbR/Lkk4uS2xFHWEcSk/miVTzZunUXH320zhJdBeZbohOR4bi7CNQInez9\n1JC/FbBEF4ctW+CNN1xie+01qyNpKo7SynoNH36MD1GZTOFXrcuTgceAHcA/geOBY4E/AIcBZ+AK\nLv8TWOFHjNnA6kgaY7UrTen8OqMb5f3sp6rzROQp4FhVfQBARG4AHgfOB+yrWIjQOpLTp8OqVfGv\nW7u26/bfr58bBmB1JE0uUIVvvilZvcCSnAnyK9F1Aj5U1XmRZqrqLyJyCbAauB24NJ3BZZry1JFs\n1arorO2kk6yOpMk9gYAwceIZAEya9BFgSc4U51ei2x+YH/L3XgARqRG84aqq7hCR+UAvH+Lz1d69\n8M47Rcntk0/iXze0jmTfvq7HpDG5rlKlABMnnkEgIJx0UjNLcqYYvxLdFiC0k/pm72dTIHxUV4O0\nROSzYB3J6dNdHcnNm0tfJ8jqSBpTlOzEugibMH4lum8pXufyU+9nH7xEJyI1gBOB79MbWnpYHUlj\nks+SnInEr0Q3DxgpIvVVdSMwDdgF3Cci+wFrgBG4s7mXfYox6cpbR7JPH5fYeve2OpKm4lHvm6Al\nM5MovxLdC8AJwHHAdFXdICI3AQ8Ct3nLCPAD8Cd/QkyOr74qOmtLtI7k0UcXnbV16mR1JE3FFRxC\nsGXLTh58sI8lO5MQv2pdvg10Dpv2kIi8DwwG9sPdomeCqiYw7Nl/u3fD/PlFye2LL+JfN1hHsm9f\n92hW2k2MjKkAIo2Ts2RnEpFRtS5VdT7Fe2NmjXfegb/9zdWR/Pnn+NezOpLGRBcpyT300CJEhAcf\n7ONjZCabZFSii0REmqvqGr/jiOXjj2H4cFdfsjRWR9KY+MSqeNK2bYXojG2SJGMTnYg0wV2fG0rx\nepgZZ+7c2EnugAOK15GsUydtoRmTlaysl0mmtCc6EakPNATWeT0uw+c3Bm7BVUOpRlGB54y1c2fJ\nacceW5TcOna0OpLGJOLuu+dbkjNJk7ZEJyLtgPG4npbBae8Cv1XV5SISwCW4G4E8XK/LJcDN6Yox\nWS69FB57zO8ojMleJ5zQjBo1KrNjx97CaZbkTFml5TzDa4aci0tyEvLoDMwUkQbAdGAMkI8bND5Y\nVY9T1TfTEWMy2dmbMeXTrdvBTJ16PjVquO/iluRMeaTrjO5aoA5uIPjdwEe4G632B64A5gBtcLft\nuRkYp6oJ3HDGGJNrgslu5crNjBjRwe9wTBZLV6LrgUtiXVR1Vcj0mSKyAbgDdy2uv6rOSVNMxpgM\n163bwcDBfodhsly6GtkOBt4NS3JBz3g/l1iSM8YYk2zpSnQ1cYWcSwgZIxd+1wJjTA5TVbZsidBl\n2ZgkS2e3idKGUydQBdIYk82C4+Tatx/PqlUl7w5uTDJZ/0BjTFqFDgZfvXorXbpMtGRnUiqdie4C\nEdkW6YHriBJt/tY0xmiMSaFIFU9Wr95K165Ps337Hh8jM7ksnZVRqniPROdnfGUUY0zpYpX1uuWW\nk8jLi3V4MKbs0pXoTk/TfowxGchqVxo/pSXRqeq0dOzHGJOZnn76Q0tyxjfWGcUYk3KDBrWhS5cW\nxaZZkjPpYonOGJNy+flVmTp1SGGysyRn0ilj70dnjMktwWT35psrGTDgCL/DMRWIndEZY9ImP7+q\nJTmTdpbojDHG5DRLdMaYpFBV3n33O7/DMKYES3TGmHILjpPr3PkJHnroPb/DMaYYS3TGmHIJHwx+\nzTWvW7IzGcX3RCci1USkk4icLiJZeRthtSJlpoKKVvHk//7vdZYvX+9TVMYU51uiE5EaIvIg8BOw\nEPgf8PuQ+ZeIyBciYoNtjMlAscp6TZjQn7ZtD/AhKmNK8iXRiUg1YBYwEtgDzAckbLGZwKHAWemN\nrvwk/JkYk2OsdqXJJn6d0V0NdAZeBg5W1S7hC6jqd8AKoHt6QzPGlObDD9dx552W5Ex28CvRDQHW\nAxepaqw7Ln4ONE1PSMaYeLVv34iJE88s1nphSc5kKr8S3eHAIlX9tZTlfgUapCEeY0yCLr64HRMn\nnkmlSmJJzmQ0vxKdUvKaXCQHAjvKsyMRuUpEVorIDhF5V0SOLWX5qiJyt4isEpGdIvKNiAwrTwzG\n5KqLL27H55//3pKcyWh+FXX+BmgnIgFVLYi0gIjUAI4GPivrTkTkXOB+4LfAImAUMENEDlfVjVFW\nm4I7i7wE+BpoTAYMwzAmUx166H5+h2BMTH4dwKcCTYDrYixzI1APeKUc+xkFTFDVZ1T1c+B3wHZg\neKSFRaQPcDLQV1XnqOoaVX1PVd8pRwzGGGN85FeiG4vrjHKPiEwSkQHe9P1FpJeIPA78CfgeeLgs\nOxCRKkBH4M3gNFVV3LCGzlFWOx1YAtwoIt+JyAoR+auIVC9LDMZkM1VlwoQlbN5crqsHxvjOl0Sn\nqj8BfYEfgPOBl3DX7foDr+HOuNYBA1R1Wxl3Ux+o5G0n1DqgUZR1WuLO6NoCZwLXAAOBcWWMwZis\nFBwn97vfTaNXr0mW7ExW8+3Gq6r6voi0AS7HJb2WuMT7LS7Z/bOUoQepEAAKgPNV9RcAEbkWmCIi\nV6rqrkgrzZ8/CqhT+Pfrr8PkyUMYMmRIGkI2JrnCB4MvWfIDvXpN4o03LqRevRo+R2fKa/LkyUye\nPLnYtK1bt/oUTXqI5mihRq/pcjtwjqq+EjJ9IlBHVUtUXPHmnaCqh4dMawUsBw5X1a/Dlu8ALD33\n3KX85z9FZTovvxzGj0/u8zEmHWJVPJkyZRADB7bxISqTasuWLaNjx44AHVV1md/xJJtfJcDyU70P\nVd0DLCWksoqIiPf321FWWwgcKCJ5IdOOwJ3l2Y22TE4rrayXJTmTrfzqjPKjiDwpIqekeD9jgctE\n5GLvzGw8kAdMBBCRe0Tk6ZDl/40rMv2UiLT24vsL8ES0ZktjcoHVrjS5zK9ElwcMA+aIyJcicouI\nJL3Ul6o+jxvCcAfwPm5cXm9V3eAt0ghoFrL8r0BPoC6wGHgWV4/zmmTHZkwm+fXXPUyZ8mmJ6Zbk\nTC7wK9E1A24FvgIOAe4EVorI6yIyWESqJmtHqvqwqrZQ1Rqq2llVl4TMu0RVu4Ut/4Wq9lbVmqp6\nkKreYGdzJtfVrFmV2bOH0rp1/cJpluRMrvBreMEPqnqPqh4BnAQ8hes40guYDKwVkX/aveiMSZ9G\njWoye/ZQ2rRpYEnO5BTfhhcEqerbwNsiMhIYhGvSPBW4ErhCRD5R1XY+hmhMhdGoUU2WLfst1ar5\nfmgwJmkypoajqu7wSnV1w42pexhX+PlIfyMzpmKxJGdyTUZ9okUkAPTDndX18zcaY4wxuSAjzuhE\npK2I/A1X2/J/wFnAPmASWXCH8Rwdc29yjKoyZsxc/ve/z/0OxZi08u2MTkTq4upcXgJ0oOj+dO8B\nTwLPqerPPoVnTE5RVW6/fS533vkWlSsHmDJlEGee2crvsIxJC78qozwPrAX+gbvDwHrgb0AbbwjA\nY5bkjEmO0CQHsHdvAYMGTbEzO1Nh+HVGNxDYi7vX3JPAdFXd51MsSSfx3DvdmDQIT3JBe/cWsGHD\nrz5FZUx6+ZXorgMmqep6n/ZvTM6LluTABoObisWXRKeqY/3YrzEViSU5Y5yM6HVpjEm+QKBkG7ol\nOVMRpeWMTkQewt1B/C5V3eD9HS9VVSuqbEyCRo/uAsCYMfMAS3Km4kpX0+XvcYluHLDB+zteit09\nwJgyGT26CyJw4IG1LMmZCitdiW6k9/PHsL+NMSl2++1d/A7BGF+lJdGp6rhYfxtjjDGpYp1RjMli\nqsrevQV+h2FMRvOrMso2ESn1rE5E/iEiW9MRkzHZJjhO7uyz/8OuXXv9DseYjOXXGV1NoEYcy1X3\nljXGhAgdDP7qq18waNAUS3bGRJHpTZc1cKXCjDGeSBVPXn31CwYP/i9qt9IwpoSMTXQikgecQFFP\nTWMqvFhlvfr3PwyxQqvGlJC2EmAi8lHYpDMiTAuqDDTHndE9mdLAjMkSVrvSmLJJZ63LI0N+V6Ce\n94hGgRnAzakMyphs8de/vm1JzpgySGeiO8r7KcBHuDuJ/ynKsruBH1TV7iNijKd//8MZO/Yd1q0r\n+rewJGdM6dKW6FR1efB3EXkBmB06zRgTW5s2DZg9eyjduj3NunW/WpIzJk5+3aZnkB/7NSbbBZPd\n4sXfM3Roe7/DMSYr+HXjVWNMGbVp04A2bRr4HYYxWcNu02OMMSan2W16jMkgqsr33/9M06a1/Q7F\nmJxht+lJARuza8oiOE7u739/j5kzL+K445r4HZIxOcFu02NMBggfDN6z57OW7IxJkowtAWZMRRGp\n4sm2bbvo3XsSP/203cfIjMkNGZfoRKShiHQXkUP9jsWYVItV1usvf+nB/vvn+RCVMbnFr/vR9RaR\nZ0SkY9j0q4A1wBvAigR7ZxqTVax2pTHp4dcZ3SXAYOCr4ATvDO5B3HXDr4E9wFUi0seXCI1JsZde\n+tySnDFp4Fei+w3woaqG3j38QqAScK2qHg4cDxQAl/sQnzEpd8YZR3Dxxe2KTbMkZ0zy+ZXo6gPf\nhU3rAuwAJgCo6ofA28DRaY3MmDSpVCnAk08OKEx2luSMSQ2/SoDl4ZomARCRAO4sb5Gq7gxZ7lvg\n2DTHZkzaBJPdsGHt6Nr1YL/DMSYn+XVGtwE4JOTv43DJ7+2w5aoD1r/a5LRKlQKW5IxJIb8S3btA\nBxHpLyJVgBtwpb7eDFvuCOCHdAdnjDEmd/iV6P6G62jyMu6M7UxguarODi4gIo2BNsBSXyI0JglU\nlWnTvkBV/Q7FmArLl0Snqu8AZ+OS2PfAf4F+YYtdjEuGc9ManDFJEhwn17//ZEaOfM2SnTE+8e1+\ndKr6KvBqjPn3AfelLyJjkid8MPi4cYsB+Mc/TkOs6rcxaZVxJcCMyXbRKp6MG7eYhQu/9SkqYyou\n3+8wLiJHAl2BYJn274E5qvqJf1EZUzallfU66aTmPkRlTMXmW6ITkUbAU0CvKPNnAMNV9cdI843J\nNFa70pjM5EuiE5FawBzc8IG9wDxcfUuAlrgqKX2AN0XkeFX9xY84jUnEqlVb+NvfwoeCWpIzxm9+\nXaMbhUtyc4FWqtpTVX/nPXp582YDrbxljcl4Bx9cj+nTL6BGjaLvj5bkjPGfX4nuHOAn4AxV/SZ8\npqquBM4CNgED0xybMWXWpUsLpk+/gPz8KpbkjMkQfl2jOwR4TVV/jraAqv4sIvNwTZgZzYZHmVBd\nurTg66+vpmHDmn6HYozBvzM6Tde+ReQqEVkpIjtE5F0RiatItIicKCJ7RGRZqmM0uceSnDGZw69E\n9xVwqtcpJSIRqY0bdvBVtGVKIyLnAvcDtwPHAB8CM0Skfinr1QGeBmaVbb9lWcsYY0wq+JXoXgT2\nA/4nIiXKtovIIcBLQF1cebCyGgVMUNVnVPVz4He42prDS1lvPPAvXPFpYwqpKmPHvsM332z2OxRj\nTJz8SnQPAJ/jzthWiMgcEXnSe8wFPvPmfe4tmzDvrggdCbkjgrpig7OAzjHWuwQ4GBhTlv2a3BUc\nJ/eHP7xB165PW7IzJkv4VdT5F1wim47rEHMqMMx7nOJNmwZ0U9Vfy7ib+kAlYF3Y9HVAo0griMhh\nwJ+BC1S1oIz7NTkofDD4mjVbLdkZkyX8LOq8DugvIkfgBoiHlgCbq6or0hmPd5fzfwG3q2pw8Lpd\nbTNRK56sWbOVt9/+lpYt6/kUmTEmHr7XuvQSWiqS2kZgH9AwbHpDIFJZsVrAb4D2IjLOmxYARER2\nA71UdW6kHS1YMAqoU/j39OkwefIQhgwZUq4nYPxXWlmvCy882oeojCm7yZMnM3ny5GLTtm7d6lM0\n6SHpvEeWiNTANVm2AHYBH6hqym6sKiLvAu+p6jXe3wKsAR5S1b+GLStA67BNXOXFew6wSlV3hK3T\nAVg6aNBSpkzpUDj9yith3DhMlrPalaaiWLZsGR07dgToqKo5N6QqbWd0ItIXV8S5ftj0hcAgrykz\n2cYCE0VkKbAI1wszD5jo7fse4EBVHep1VPk0LLb1wE5V/SwFsZkMt2dPAQsWrCkx3ZKcMdklXYO2\nWwEvAA1w1712BWcBJ1K+IQRRqerzwHXAHcD7wNFAb1Xd4C3SCGiWin2b7Fe1aiWmTj2frl1bFE6z\nJGdM9klXr8trgWrAfOAoVc0D8oEhwGbgBBE5KRU7VtWHVbWFqtZQ1c6quiRk3iWq2i3GumNUtUO0\n+Sb35eVVYerU8+ne/WBLcsZkqXQ1XXbBFWg+U1U3A6jqTuA/IlId16R5KrAgTfEYE7e8vCq88cZF\nBALWCdeYbJSuM7omwKJgkgszPWQZYzKSJTljsle6El0NInfpJ+R6WfU0xWKMMaYC8asEmDEZQVW5\n7bY5PPDAO36HYoxJkXQOGN/fG3eW8PxcHNdh/BdpnNyoUVHLoBpjslQ6E11/7xGJxpivZEAFF5Nb\nIiW5a699A7BkZ0yuSWcCKevVfOsFYJIqVsWTmjWr+hCRMSaV0pXoot5g1Zh0srJexlQ8aUl05bjV\njjFJNWbMPEtyxlQw1uvSVCiHHrofEtYYbknOmNxmiS4J0ngDCFNOF154NM88c1ZhsrMkZ0zus96M\nKRB+xmAyS/Aecjt27LEkZ0wFYInOVEh2w1RjKg5rujTGGJPTLNGZnKOq7Nixx+8wjDEZwhKdySnB\ncXInnfQUmzbt8DscY0wGsERnckboYPBly9bSs+ezluyMMf4nOhE5RURuEpH7ReT8kOm1ReRAEevD\naEoXqeLJsmVr6dXrWfbs2edjZMYYv/mW6ESklYi8D8wB/gz8H9AjZJEzgW+BPj6EZ7JIrLJel1/e\nkSpVKvkQlTEmU/iS6ESkES7BtQPmA3dQsnjzi8Be4Iz0RmeyidWuNMaUxq8zuluAhsCtqtpFVUeH\nL6CqvwAfAZ3SHJvJIuPGLbYkZ4yJya9E1xf4SlXvKWW5lUDjNMRjstSgQW1o06ZBsWmW5IwxofxK\ndE2BD+NYbh9QJ8WxmCzWsGFNZs++uDDZWZIzxoTzqwTYdqBeHMu1ALakNhST7YLJbu7cVZx77pF+\nh2OMyTB+ndF9AnQUkbrRFhCRJkB7YFnaojJZq2HDmpbkjDER+ZXoJuOaJMeLSNXwmSISAB4CqgL/\nTnNsxhhjcohfie5x4D1gMPCJiIz1prcVkT8Dy4GzgIVYoqvwVJVPP93gdxjGmCzlS6JT1T3AacCr\nwKG4weIAxwI3AUcAM4ABqlrgR4wmMwTHybVrN54XX/zM73CMMVnIt/vRqeoW4AwR6Qj0A1riEu+3\nwGuqusCv2ExmCB8Mfu65/+U//xnI2We39jkyY0w28f3Gq6q6FFjqdxwms0SqeLJ3bwHnnfdfvvxy\nJAcdFLUfkzHGFON7UWdjwsUq6zVuXF9LcsaYhPhyRici+yWyvKpuSlUsyaDqdwS5w2pXGmOSza+m\ny0S60CkZ0MRq0mPevNWW5IwxSeVX0+VmYFOExxbcXQyCj03eslnF7qBXdl26tGDMmC7FplmSM8aU\nh1/DC+qraoMIj/2B2sD5wFrgOVVtEHtrJtfcdtuphcnOkpwxprwyrknQuz3PcyLyNbBQRJao6tN+\nx2XS67bbTuX00w/nmGPs5hXGmPLJ2F6XqroYN+zgKr9jMf6wJGeMSYaMTXSeNYCNDjbGGFNmmZ7o\n2gJWAizHqCr/+tdH7Nq11+9QjDEVQEYmOhGpKSL3A22ARX7HY5InOE7uwgtf4pxznrdkZ4xJOb8G\njH8UY3Yt4EBcbHuBO9ISlEm58MHg06Z9yTnnPM8LLwymWrWM6xdljMkRfh1dSrtDpuJu43OLqs5P\nQzwmxaJVPJk27UvefHMlffse5lNkxphc51eiOyrGvN3AWm+YgckBpZX1siRnjEklXxKdqi73Y78m\n/ax2pTHGb750RhGRj0TkJT/2bdJr48btPPpoybswWZIzxqSLX70uDwV2+rRvk0YNGuQzd+4wGjbM\nL5xmSc4Yk05+Jbo1QH6pS5mc0KpVfebOHUbjxjUtyRlj0s6vzigvAVeISD1Vzbq7E5jEtWpVnxUr\nfk+tWtX8DsUYU8H4dUZ3F7AamC4i7XyKwaSZJTljjB/8OqObDPwEdAGWishKYBWwI8KyqqpnpC80\nY4wxucSvRNc/5PcAcIj3iETLsyMRuQq4DmgEfAiM9O6MEGnZs4ArgPZANWA5MFpV3yhPDLlOVbnn\nngV063YwnTo19TscY4wpxq9Ed3o6diIi5wL3A7/F1cwcBcwQkcNVdWOEVU4B3gBuxt3tfDjwqogc\np6ofpiPmbKOqjB49lzvueIvatasxY8aFluyMMRnFrwHj09K0q1HABFV9BkBEfgf0wyWwv0SIa1TY\npFtF5AxcYrZEFyY0yQFs27aL3r0nWbIzxmSUtHRGEZHZInJDOvYVss8qQEfgzeA0VVVgFtA5zm0I\nrsj0pljLabkaV7NTeJIL2rZtF59+usGnqIwxpqR09brsArRK076C6gOVgHVh09fhrtfF43rceL/n\nE9mxSCJLZ59oSQ7cYPDhw4/xISpjjInM7o0ShYicD/wJGBDlel6FVFqSs8HgxphMk8uJbiOwD2gY\nNr0h8GOsFUXkPOBRYKCqziltR2+/PQqoU/j31KnQufMQhgwZkmjMGU8V1qzZVmK6JTljssPkyZOZ\nPHlysWlbt271KZr0yNlEp6p7RGQp0B14BQqvuXUHHoq2nogMAR4HzlXV1+PZ1wknPMCLL3Yo/Lt/\nf8jBHAdAICA8/rjrNDtx4geAJTljssmQISW/hC9btoyOHXP3fzhnE51nLDDRS3jB4QV5wEQAEbkH\nOFBVh3p/n+/NuxpYLCLBs8EdqlryNKaCqlQpwOOPn44IdO7c1JKcMSajpTPRDRWRoWVYT1W1THGq\n6vMiUh+4A9dk+QHQW1WD3QIbAc1CVrkM14FlnPcIeho3JMF4KlUK8MQTA5Bc73ljjMl66Ux0vhwR\nVfVh4OEo8y4J+7trWoLKEZbkjDHZIJ2J7nXgvjTuz5SDeoMDLZkZY7JdOhPdj6o6L437M2UUHEKw\nYcN2xo3ra8nOGJPVcr0ziklQpHFyluyMMdnMr/vRmQwUKck98sgSRo58zceojDGmfCzRGSB2xZN2\n7cLH3BtjTPawRGesrJcxJqel5RqdqlpCzWB33z3fkpwxJmdZAjKcfHJz8vKqFJtmSc4Ykyss0RlO\nPbUF06efX5jsLMkZY3KJDS8wQFGy++qrTYwY0aH0FYwxJktYojOFTj21Baee2sLvMIwxJqms6dIY\nY0xOs0RXQagqmzbt8DsMY4xJO0t0FUBwnFz79uP5+utNfodjjDFpZYkux4UOBv/222107fq0JTtj\nTIViiS4FMqX+caSKJ99+u41u3Z7h1193+xiZMcakT9y9LkWkOVA/hbFko1YAmzd/Vmzi+vWwbJkv\n8RRSVSZMWMJjj5UM5KKLDmXFik98iMoY44f69evTvHlzv8PwjQRvsBlzIZHmgUBgRUFBQfU0xGSM\nMSaJ8vLy+Oyzz6Imu2XLltGxY0eAjqrq89f05Iv3jK5+QUFB9UmTJtG6deuUBmSMMSZ5PvvsMy68\n8EI2btxYYc/qEhow3rp1azp0sKoZxhhjsod1RjHGGJPTLNEZY4zJaZbojDHG5DRLdMYYY3KaJTpj\njDE5zRKdMRXMI488Qp06ddi8ebPfoZgy2LlzJ02aNOHOO+/0O5SsYYkugnnz5hEIBBg7dqxvMbRo\n0YJAIFD4qFatGi1atODSSy/l22+/9S2ueF1yySXF4q9cuTINGzZkwIABLFy4MOp6u3fv5qGHHuLE\nE0+kXr161KhRg8MOO4wrr7ySlStXxtzniy++yIABAzjwwAOpVq0a9erV48QTT+Tee++1g7pn27Zt\njB49mj/84Q/Uq1fP73Ay2jPPPEOHDh3Iy8ujUaNGXHbZZWzcuDGhbbz22mv06NGDxo0bU7NmTVq1\nasX111/P+vXriy23evXqYv8voY+jjz662LLVq1fnpptu4q9//Svr1q0r9/OsCOzGqxlKRGjWrBn3\n3nsvqsovv/zC/Pnzeeqpp3j99df5+OOPM/5AJSKMHz+e/Px8du/ezfLly5kwYQIzZszgzTff5KST\nTlhnctcAACAASURBVCq2/Pr16+nTpw8ffvghPXv2ZMyYMdSsWZMPP/yQiRMn8vTTT/Pcc89x+umn\nF1tvx44dDB48mGnTptG2bVsuv/xyDjroIH755Rfeffdd7rzzTv73v//x7rvvpvPpZ6Rx48axdetW\nrrrqKr9DyWgPPPAAf/jDH+jatSsPPfQQ3333Hffffz/vvvsuixYtokaNGqVu47HHHuPyyy/nN7/5\nDTfddBP5+fksXryYBx98kJdeeomPP/64xHbOPvtszj777GLT6tatW2LbI0aM4NZbb2Xs2LHcd999\n5XuyFYGqlvoAOgC6dOlSrQjmzp2rIqL333+/bzG0aNFCjzrqqBLTr732Wg0EAjp27Fgfoiry888/\nx5w/bNgwDQQC+tNPPxWb/sorr6iI6IABA0qsc/LJJ2sgENDHH3+8xLyVK1dq8+bNNT8/Xz/99NNi\n8y666CINBAJ64403Rozlxx9/1FtvvbW0p5Q2O3bs0L1796Z9vwUFBdqiRQs988wzk77tPXv26M6d\nO5O+XT9s3LhR8/PztVOnTlpQUFA4/dVXX1UR0XvuuSeu7RxxxBHapEkT3b17d7Hpf/zjHzUQCOjL\nL79cOG3VqlUqIjpmzJi44xw6dKgecMABJbYfbunSpVra8Tu4DNBB48gJ2fZIetNlQQFs2JD+R0FB\nsp9JfH766SeuuuoqmjdvTrVq1WjevDm///3v2bSp5K1wVq9ezTnnnEOdOnWoU6cOZ511FqtXr6ZF\nixZ069Ytrv11794dVeXLL78sMW/btm3ceOONHHbYYVSvXp0DDjiA888/P2KTXyKxBAIBhg8fzuzZ\nszn55JOpVasWAwYMiPMVKhk/UCL+V199lQULFjB48GBGjBhRYr0WLVowfvx4tm/fzu233144/eOP\nP2bSpEl07tyZe++9N+I+GzZsyF133RVXfB988AGDBg2iUaNGVK9enebNmxd7DYNNTHfccUeJdUeP\nHk0gEGDNmjWF04YNG0YgEGDjxo0MHz6cRo0aUbNmTT755BNq1KjBwIEDI8Zx8803EwgE+Oijjwqn\nJfL+RrJo0SJWr15N3759S8xbsWIFV155JUceeSS1a9cmPz+f3/zmNzzxxBNRn+enn37KtddeS7Nm\nzahRowbvvfde4TKzZs2id+/ehc3P7dq1Y8KECSW2NXPmTM477zwOOeQQ8vLyqFevHr179+att94q\nsWy6vPTSS+zYsYORI0ciIbci6d+/Py1btmTSpElxbWfbtm3Uq1ePKlWqFJveuHFjAPLz8yOut2vX\nLnbsKP0myaeddhobN25kzpw5ccVTkSW96fKnn+CAA5K91dKtXw8NGqR3n9u2baNz58588803jBgx\ngmOOOYb333+fRx55hDlz5rBo0aLCD/OmTZs46aST2LBhA1dccQWtWrVi/vz5dOnSJa4PddBXX30F\nwH777Rcxlu+++47hw4fTtm1b1q5dy8MPP0ynTp1YsmQJzZo1K3Msixcv5oUXXuCyyy5j2LBhZXi1\nYsf/wgsvICJcdtllUdc97bTTaNq0KdOmTWPPnj1UqVIlrvXiNXXqVAYOHEjNmjW57LLLOOSQQ/jx\nxx+ZMWMGn3zyCQcffHDM9UWk2IExdFrPnj1p3Lgxt912G9u3b6dZs2YMGDCAV155hS1bthRrnlJV\n/v3vf9O+ffvC6zOJvL/RzJs3DxHhuOOOKzFv7ty5LFiwgNNPP52DDz6YX3/9lSlTphRel7rxxhtL\nPKcLLriAvLw8rrvuOkSk8AD+6KOPcsUVV9C5c2f++Mc/kp+fz8yZM7niiiv45ptvijW1TZw4kc2b\nNzN06FCaNm3K999/z+OPP06PHj2YM2cOJ554YsznFHxt9uzZU+py4Iobl9bsuGTJEgA6depUYl6n\nTp147rnn2L59O3l5eTG307t3b5555hmuu+46Lr30UmrWrMmiRYu466676NKlS8Qvt/fffz9jxoxB\nVWnatCmXXHIJt956K1WrVi2xbOfOnVFV5s6dS69evWLGUuHFc9pHAk2X69erQvof69eXGlrc4m26\nvOWWWzQQCOj48eOLTR83bpyKiN52222F066//noNBAI6efLkYsvecMMNKiLatWvXYtNbtGihbdq0\n0Y0bN+rGjRt11apV+uyzz+p+++2nVatW1Y8//rjY8ldffbXm5eWVmL5mzRqtXbu2XnLJJWWORUQ0\nEAjo7NmzY74eoYJNl1988YVu3LhRf/jhB505c6a2a9cu4mvWsWNHDQQCunnz5pjbHTBggAYCAV2+\nfLmqqp5zzjkaCAT0/fffjzu2SLZv367169fXRo0a6dq1a6MuF6uJafTo0RoIBHT16tWF04YNG6Yi\nohdffHGJ5adNm6Yioo888kix6bNmzVIR0QcffLBwWiLvbzRDhw7VQCAQsdl5+/btEdfp0qWL1q1b\nt1hT6+jRo1VEtFu3brpv375iy69du1arV6+uF154YYltXXPNNVq5cmVduXJlzP2uX79e69evr/36\n9Sv1OQVjFJFSH4FAIK6mwdNPP10DgUDEptgbbrhBA4GAfvnll6VuZ9u2bTp48GCtXLlysThGjBhR\noul6zZo12uP/2zv38KqKq3G/6wRIAiTkx1VAlKICIgJKESiighSwLaIRFVBEKRqrVYufhaoIQlUU\nysUrFMItVZBSxKrwFUQRi0LRgvUGaEHwE6EGKgHDHdbvj9knnGtyTu4c1vs8+0kys2Zmrb139toz\ns2ZPjx763HPP6euvv66zZs3S3r17q4hoz549g4ZQA6latWrEaYBAbOhSLRilJLz66qvUq1cvrDeR\nlZXFmDFjWLx4MWPGjAFcb6Fhw4b0798/SPaBBx5gwoQJEevftGkT9UK6qeeddx7z5s2jdevWQenz\n5s3jsssuo2HDhuzZs6cgPTU1lU6dOrF8+fKCtOLo0rZtW7p16xYxLxqqSosWLYLSMjIymDBhAllZ\nWUHp+/btA6BWrVqF1pmeng5AXl5eUDl/enFZtmwZe/bsYfz48ZxxxhklqisUEeGBBx4IS+/VqxcN\nGjQgJyeHO++8syA9JyeHqlWrMnDgwIK0eK5vNHJzc6lSpQo1a9YMywvs5Rw+fJj8/HxUlZ49e/Lu\nu++yadMmLrjggiCbfvOb3+DzBc9+LFy4kCNHjjBkyJAgPcEN/T3zzDOsWLGCoUOHhrWbn5/P4cOH\nERE6duwYNBRaGJMmTYo5qrZZs2ZFyhw4cACA5OTksLyUlJQgmcKoUqUKZ511FpmZmfTp04fq1auz\nbNkyZs6cic/nY/r06QWyTZo04c033wwqf9ttt5GVlUV2djYvv/wyAwYMCGujdu3aYRGcRjjm6ErA\nV199RYcOHcL+2ZOSkmjevDkbNmwIku3YsWNYHfXq1YsYVQVuXio7OxtVZdeuXUydOpWPP/6YpKSk\nILnc3Fz27NnD8uXLwxwjuIdSYJni6NK8efOI6YUhIrzyyiukpaWxf/9+Xn31VV588UUOHToUJhvo\nwKLpAOEO0V9u//79cesXyJdffomI0K5duxLVE43zzjsvLC0pKYmbbrqJyZMn8+9//5tzzz2XAwcO\nsHjxYnr16lVwLeO9vtEIHVYNJD8/n9GjR7Nw4cKw5SsiEtGRRLJp06ZNqGrBXGwkHQJD4rdu3cpD\nDz3E8uXL2bt3b5Bs6P9VNC666KKY5GLFPyR5+PDhMGfnv3eLGrZUVXr16sWJEydYvXp1QXpmZia1\na9dm/Pjx9O/fv8i5+YcffpgZM2awZMmSiI5OVQu9roaj1B1dnTpuvqy8qVOn/Nssa2rUqBHUi7ru\nuuvo1KkTN954I59//jkNGjQA8A8v06NHD373u98V/F2aFPWPHY2uXbsWzMf17duXlJQURo4cSfv2\n7enVq1eBXOvWrdmwYQPr168v9J9/w4YNpKSkFDxkW7duzeLFi9mwYQNt27Ytlo7xUNhD5dixY1Hz\n/D2BUG655RYmTZpETk4OY8eOZdGiReTn5zN48OACmdK6vvXq1ePYsWPs37+ftLS0oLwBAwawdOlS\nsrKy6Nq1K3Xq1CEpKYklS5YwZcoUTkSI9op0T/gfvH/605+i9oz9var8/Hy6du3KwYMHGTZsGK1b\ntyYtLQ2fz8cTTzwRc5DF999/z5EjR2KSrVmzZtQgED+NGjUCYMeOHWE9wB07diAiBTLRWL16NatX\nr2bixIlheddffz1PPfUUq1atKtLRNWnShKSkpKjr977//vuILz9GMKXu6Hy+8g8KqSiaNWvG5s2b\nOXHiRNDb5/Hjx/niiy+C/kmaNm1aEIgRSG5ubtibbDSSk5OZPHky3bt3Z/To0UybNg042RPbt29f\nTMOLpaFLcRk3bhwLFizg/vvv59NPPy1wHJmZmeTk5JCdnR31n/9vf/sb33zzDf369SuIZMvMzGTs\n2LHMnDmzREEyzZs3R1X56KOP6NGjR1Q5v9OOFFW7ZcuWuNtt06YNbdu25cUXX2Ts2LHk5OSQkZER\ntFYw3usbDf9w95dffhm0r2ReXh5Llixh8ODBPP/880FlYhkSDcT/AlKnTp0iH+JvvfUWO3fuZM6c\nOdxyyy1BeQ899FDMbWZmZrJq1aoi5USE0aNHM2rUqELlOnTowPTp01mzZk2Yo1u7di0tWrQo8sVv\nx44dgHsWhOJ/ISrsxcjPli1bOH78eMFLbSDbt2/n2LFjYdMYRjj2ZZQScM0115Cbm0t2dnZQ+vTp\n08nNzQ1a+NmnTx927tzJ/Pnzg2SjzYlF44orruCyyy5jzpw5bN++HaAgAm7dunUsWrQoYrnc3NxS\n16U4ZGRkcO+997Jp06ag9q+++mq6dOnCggULmD17dli5bdu2kZWVRWpqKo8++mhBeps2bRg0aBDv\nv/8+Dz74YMQ2d+3axcMPP1yoXj179qRu3bpMnDiRXbt2RZWrWbMmZ5xxBm+//XZQ+tatW/nrX/9a\naBvRGDx4MNu3b2fevHmsXLmS/v37B0XZxXt9o3HFFVegqmEL5/3DnqG9tp07d0ZcXlAYN9xwA9Wq\nVWP06NERh6j37dtX0PuK1u7y5ctZt25dzG1OmjSJFStWFHm8+eabYQ41En379iU1NZXnnnsuqPf8\n+uuvs3XrVm6++eYg+T179rB58+aCYXWAVq1aAfDSSy+FObTZs2cjInTo0KEgLdKLk6oycuRIRCTi\ncp61a9ciIlx++eVF2nTaE0vECqfpgvGrrrpKH3vssbDDHzGYl5enzZs31ypVqugdd9yhU6dO1dtv\nv12TkpK0VatW+sMPPxTUuXv3bm3cuLEmJyfrfffdp1OnTtWBAwdq06ZNtX79+tq9e/cgHaItGFc9\nGZU3dOjQgrS8vDy9+OKLNSkpSfv3769TpkzRF154QUeMGKEXXnhhUFRevLqISExRfYFEWzCuqvrf\n//5X09PTtWXLlkHRZDt37tSLLrpIfT6f9u7dW5955hmdOXOm3nvvvZqenq41atTQ1157Lay+AwcO\nFERjXnjhhfroo4/q7Nmz9dlnn9VBgwZpjRo1tHPnzkXq/Nprr2lycrLWqVNHR4wYoTNmzNDHH39c\nL7/88qB2H3/8cRUR7d27t06bNk0feeQRrV+/vnbs2DFi1KXP5yu03e+++06rVq2qtWrVUp/Pp2vX\nrg2Tief6FsY555wTMZqxd+/empSUpFlZWZqdna0jR47U+vXr6yWXXKI+n09XrVpVIBspujSQ2bNn\na5UqVbRp06b6yCOPaHZ2to4bN04HDBigNWrUKCi3d+9ebdiwodauXVtHjRql06dP17vuukvT0tK0\nTZs2RZ63smTixInq8/m0W7duOn36dB01apTWrFlTL7jgAs3Pzw+SHT16tIqIzp07Nyi9X79+6vP5\ntG3btjphwgR9/vnntU+fPioi2qVLl6B7PzMzU3v06KGjRo3SGTNm6Lhx4/THP/6x+nw+zczMjKjj\noEGDbMF4jIc5ugi888476vP5oh7nn39+gezu3bv17rvv1iZNmmi1atW0SZMmes8990R8wG/btk2v\nu+46TU9P11q1amnfvn1169atEUOpmzZtqm3atImqY+fOnbVatWq6devWgrSDBw/qY489pm3atNHq\n1atrenq6tmrVSu+44w5dt25dsXXx+Xw6ZMiQuM7hrbfeqklJSRHPg6rqgw8+qD6fT3NycoLSDx8+\nrE8//bR27txZMzIyNDU1Vc855xy96667gmyNxCuvvKJ9+vTRhg0barVq1TQjI0M7deqkTz75pO7d\nuzcmvT/44AO99tprtV69epqSkqJnn322Dho0KCgk/tixYzpixAht1KiRpqamavv27fWNN96Iurwg\nKSmpyHb9jrply5ZRZeK5vtEYP368Vq1aVb8LWY+zZ88evf3227Vx48aampqqbdq00ZkzZ+qcOXPi\ndnSqqu+//75mZmZqgwYNNDk5WRs3bqzdu3fXyZMn6+HDhwvkPvnkE73qqqu0du3amp6ert26ddPV\nq1fHfN7Kkrlz52q7du00NTVVGzRooEOHDtXc3NwwOf/5CHV0R48e1QkTJmi7du20evXqmpKSoi1a\ntNCRI0eGLauYNWuWduvWTRs2bKjJycmanp6unTt3DluG4yc/P19r1qwZ9WtAgZijM0dX4ezZs0dF\nRH/1q19VtCqVShejbNi3b582aNBAR44cWdGqGCVgypQpmpaWprt27SpS1hxdGXwCzIhOpDmLcePG\nISLl/mWDyqSLUX6kpaUxZswYnn32WdvR4RTl0KFDPPXUUwwfPjxikIoRjq2jK0d+9rOfcfbZZ3Px\nxRdz4sQJVqxYwZIlS7j00kvp27fvaauLUb5kZWWFLdg3Th1SUlL49ttvK1qNUwpzdOVInz59yMnJ\n4dVXX+XgwYOceeaZ/Pa3v2XUqFHlvuizMuliGIZRlpijK0eGDRvGsGHDKloNoHLpYhiGUZbYHJ1h\nGIaR0JijMwzDMBIac3SGYRhGQmOOzjAMw0ho4gpG2bhxY1npYRiGYZQB9tyO3dHt9vl8h26++ebI\ne40YhmEYlZbq1atTt27dilajwojJ0anq1yLSAjgVz9QNwCCgDvAFMB74vBD59sAw4BxgFzATeCOK\nbEvgpW7dXmTlyvO9JOWCCz7ks8/WFwj5fMKTT/bgyiuL3t3YMAyjtKlbty5nnXVWRatRYcQ8dKmq\nXwNfl6EupY6I3Aj8BrgDWIdzYM8AzVU1bCdDEWkKTAZewDm4HsAUYI2qvhlBHoCMjPPxPgcKvMNn\nn+0CTm7MeOIEZGT8KGgPMMMwDKN8SPRglGHAH1U1R1U3AXcCB4AhUeR/BWxV1eGqullVnwf+4tVT\nBM7JwbthOdOn/4Lbb29fHP0NwzCMEpKwjk5EquKGId/yp6mqAiuAzlGKdfLyA1lWiHwA7wDPh6Um\nupML3bz1dMBsPj04HW1OVBLW0eHmE5OA/4Sk/wc4I0qZM6LIp4tIcuHNJQGfBKUkupOD0/NhYDaf\nHpyONicq9q3LUmDNmmFALSAXmAfA0KG3JLyTMwzj1GP+/PlhTjwvL6+CtCkfEtnR7QaOA6EbNjXA\nRVNGYlcU+X2qejhaQ507T2bx4ouBq4EHuPLKGsyYYU7OMIzKx4ABAxgwYEBQ2vr162nfPnGfWQnr\n6FT1qIj8E7gSeA1AXJjklbjIy0isAa4KSevppUelUyc45xxYvBiuvfYyLr20ZLobhmEYpUfCOjqP\nScAcz+H5lxdUB+YAiMg4oJGqDvbkpwF3i8hTwCycU+wH/CxK/SkAjRtvpEcPWLcujwED3Pq59euj\nlEgw8vLyWH+6GOthNp8enE42B3w9JSE/CiIuEDFxEZG7gOG4IciPgHtU9UMvbzZwtqp2D5C/DLeW\nrhXwDTBWVf8Upe6BwEtla4FhGEa5cZOqzqtoJUqbhHd0ZYmI1AF6AduAQxWrjWEYRrFJAZoCy1R1\nTwXrUuqYozMMwzASmkReR2cYhmEY5ugMwzCMxMYcnWEYhpHQmKMzDMMwEhpzdHEgIneLyFciclBE\n1opIhyLkrxCRf4rIIRH5QkQGFyZfGYnHZhG5VkSWi8h3IpInIu+LSM/y1Lc0iPc6B5TrIiJHReSU\nW3xVjHu7mog8LiLbvPt7q4jcWk7qlphi2HuTiHwkIvki8q2IzBSR2uWlr1EyzNHFiLe33URgNHAR\n8C9gmYhE3IzW29vuDdzuCW2Bp4FsEflpeehbGsRrM3AZsBz3dZmLgZXA6yLSthzULRWKYbO/XC1g\nLuG7X1R6imnzQqAbcBvQHBgAbC5jVUuFYvwvd8Fd2xm49bX9gEuA6eWisFFyVNWOGA5gLfB0wN+C\nW1A+PIr8U8DHIWnzgaUVbUtZ2Ryljk+BkRVtS1nb7F3bMbiH5/qKtqMsbQZ6A/8FMipa93Ky93+A\nL0PSfg18XdG22BHbYT26GCj/ve0qnmLaHFqHAGm4h2Klp7g2i8htwI9wju6Uopg29wE+BEaIyDci\nsllEJohIpf98VDHtXQM0EZGrvDoaANcDS8pWW6O0MEcXG+W8t12loDg2h/JboAbw51LUqyyJ22YR\nOQ94AvfppBNlq16ZUJzr3AzoClwAXAPchxvOC995uPIRt72q+j5wM7BARI4AO4Hvcb064xTAHJ1R\nJnjfAX0EuF5Vd1e0PmWBiPhw3zodrapb/MkVqFJ54QNOAANV9UNV/RtwPzD4FHmJiwsRaYWbY38U\nN/fcC9eD/2MFqmXEQaLvXlBalNvedpWI4tgMgIj0x03U91PVlWWjXpkQr81pwI+BdiLi7834cKO2\nR4CeqvpOGelaWhTnOu8EdqjqDwFpG3FO/kxgS8RSlYPi2Ps74D1VneT9/an3sfi/i8jDqhraOzQq\nGdajiwFVPQr497YDgva2ez9KsTWB8h5F7m1XWSimzYjIAGAm0N970z9lKIbN+4DWQDtcZG1b3FZP\nm7zf/1HGKpeYYl7n94BGIlI9IK0Frpf3TRmpWioU097qwLGQtBOAcnr04E99Kjoa5lQ5gBuAA8At\nQEvcsMUeoJ6XPw6YGyDfFNiPi75sAdwFHAF6VLQtZWjzQM/GO3FvyP4jvaJtKSubI5Q/FaMu473O\nNYDtwALgfNyyks3AtIq2pYzsHQwc9u7rHwFdcPtbvl/RttgR22FDlzGiqn/21tmM5eTedr1UNdcT\nOQNoEiC/TUR+jtvb7l7cm+4vVfWUWWcVr83A7biJ/ucJDkyYCwwpe41LTjFsPuUpxr2d760HfRb4\nAOckFuDmZCs9xbB3rojUBO4G/gDsxUVt/q5cFTeKjW3TYxiGYSQ0NkdnGIZhJDTm6AzDMIyExhyd\nYRiGkdCYozMMwzASGnN0hmEYRkJjjs4wDMNIaMzRGYZhGAmNOTrDMAwjoTFHZxQgIttE5EQRx72l\n0M6TXl3DS0Pv0kREdkWw+aB3buaJSKcK0quXp8vS8ixbHohIiyj32g8isklE/igi51e0nsapi30C\nzAhEveM94N9RZD4vxXYqI37d3gW+8tL+H9AB6A/cICL3qOrUCtStAG9bnIPAIVWtHrFUlLKVEMXt\nXXjQ+7sRcAnu03KDRSRTVUvFWYtIC9yOC5tUtVVp1GlUXszRGZHIVtWcilaigpmqqgUbxnoOZTbO\n2U0WkSWq+nU56vMu7gPKPxQlWMply5v7VPU7/x8iUgdYinvRmCEiZ6nq8QrTzjglsaFLw4gBdXsI\n/gr3FfuquJ21y7P9g6r6hap+G5JV5DYxhZSt9KjqHk5+PPkMnMMrDWx7ndMIc3RGiRCR60Vkloh8\nKiLfe/NZW0Rkuog0K0Z9A0XkbRHZIyJHRCTXq3uaiLSMUqa/iCz3ZA+LyP+JyBwRaV5yC0+iqnmc\n3FS0aYgOVUTk1yKyRkT2eudhk4hMFJHQTT79ZVqIyFxv/u+wiOwTka9E5DURuSlENmyeTUTG4bab\nUSAlZH7ruIjUL6Ts1V7a+mj2ikg17zocF5HzQvKqi8hwEflHgL0bReQJEcmI5XzGwccBv4edSxFp\nLSK/F5H3RGSHdy6/E5FlIhL2QiIi83FD8Aq0DDlvByLIXyIi87376pCI7BaRpSLSozSNNMoOG7o0\nio2IJOG2Z/kB9+B4E6gGXAgMBW4UkW6qGvVhGlLfE7i39yO4ecKdQC3gbNw8zXrcpqZ++SrAQqAv\nbl7nQ69MS2AQcJ2I9NHS3eU73ftZsEu8iKQAy4CuQD7wDu6cdAGGAQNFpIeqfhZQph3wd9ymnhuB\n13CbeTYGugF1gZeK0OVD4E84W497v/tRTs51RWIJ8B3QVkTaqOrHEWT64uYnV6vqlwG6NwGW4/ZZ\nzAXWena3x12/fiJymaoWuhN9HKQH/B5pN+8RwADcvfERbkPcs3Cbqf5URJ5Q1ZEB8u/g7tNrgTxg\ncUDekcCKxQVMjfP+3IDbnLWhV3dvERmhqhOKZ5ZRblT0hnh2VJ4DF3xxHLglRnkB+gHJEfLuwz24\nP4iQN85rZ3hAWg3gEG5vs6YRypwNnBuSNtFr4x2gcUjeAK+NXUD1OM7BTq/cDRHyfuzlHQduDEif\n4unxKdAwIL0qbi++Ezhn5gvIm+fV85sI7aQCPwlJ6+XVszQkPdlLP1CITdHKTvDSJ0Upt9TT8baQ\na/6Bl/4skBqQlwQ87dX5Rhzn3L87+XGgfoT8e7z8r4EqEfKvAM6KkN4K+Nart3WUNj8vRK+rOblr\neseQvLZe3ceAS0rj/8+OsjsqXAE7Ks8R4OhORDnejrO+f3r1NQ1Jj+TozvTaWBNj3fVxjjEPqBtF\nJttrZ0gcOoc5OiDDe+h95em4Fajm5dXE9WaOA90j1FcT2O3lXxOQvsJLaxGjXmXh6M730v8DJIXk\nNQSOAvuBGgHpfb0y70VpKwnXszoONIvRtkBH1yBEhyzvGu+LdH5jqNvvJB+N0mZhju4jT6feUfJv\n9urIiVcvO8r3sKFLIxKriby8YFOENLz5m17AuUAaJ+d+a3s/WwDbCmtQVb8RkZ3AJd7c02xVjI++\nYAAABmxJREFU/aKQIj1ww0/LVXV3FJlVuJ3NfwLMKqz9CLwsIi+Hqok7B5mq6h/i6ojrge1Q1bdD\nK1HVH0RkIXAHbkjyVS9rHdAdyBaRR4G/B9RZLqjqRhFZhwvw+AXw14DswTintVBV8wPSf447D4ui\n1HlcRFYD5+HO+9Y41dopEhYnshPn5DZHKyQiacDPcD2tOrh7A9wLFLh7MGZEpBHQBudkl0cRW+X9\n/Ek8dRvljzk6IxIxLS/w5sj+CNxG4Wu00gvJC+Rm4GVgODBCRHYD/8A9aF5U1e8DZP2BLr8QkROF\n1KlAvRjbD2QVJ9fRHcH1etYAy9R7nfdo7P38iuhswQ35NQ5IewLoBFyOm9s8IiL/8tqdr6obiqFz\ncZiFW6t2G8GO7lbcuZsTIt8MZ8sfROQPhdRb3PO+ADe3mIQbru6C69n9WUS6qGrYEgkRuQ6YjptP\njHQfKrHfg37891c6cCyC8w2kOHYa5Yg5OqMkDMc9IP8PuB/nlP6jqkcBRGQRLgw/plBuVV0pIk1x\nvYbLcW/Kvb2/x4rIL1T1PU/c32vchAuGKIxPYrQnkKB1dKWN98DuLiKXAD1xD/TOuHnAB0Rkkqo+\nUFbtB/AyMBm4SkTqqWquiHQGmgNbVPXdEHkfznGsooheOlFGAIogdB1dK+AtoDXwHM4BE5DfFBe0\nUwX4PW7B+TZ/L1RE+uAceLzLCfz3Vx4ne+HROBpn3UY5Y47OKAnX4x56Q1T1rQj550VIKxRVPQj8\nxTsQkXrAkziHmo2bVwLnXAE+VdUh8bZTiuzwfv6oEBl/72BHaIaqrsMNY/qjWPvhelHDRGShqv6j\n9FQNR1X3icgrwEBcj3oyJ3vosyMU8Z/3v6jqC2Wpm6ff5yLyS+AN4GYReU5VPwwQ6YsbpnxJVUdH\nqCLue9DDb+fRCr6/jFLA1tEZJcE/Bxf2hRARuQgX9VYiVDUXeND7s7m4L5SAG848DvQog3Vb8fAP\n3FBbo0jrqkSkBidfCFYWVpGqHlfVBQFy7WJo39+bSIpZ43Bm4Xo8t4pIKnAjXpBFBNn/9WRvKEF7\ncaHus1/Lcc+r34dkF3YPCs6BRxrO9M+HRnzZV9WvgC+AuiJyRfxaG5UJc3RGSdiIe+j9OjBRRM7E\n9QZiHi4SkWYicquI1IyQfbX38z/qvlCCqu4ApuEiIl+XCB/9FZFkEblGirFwPVa8IcjpOFuf9oIY\n/O1XBZ7HBUdsxq2V8+f9WkTOjaDzmcBF3p/bY2j/BC5Yo0roou44bFiJG4ZsjZs7TAPeUtVvIoj/\nGfgX0FXcRwFqhwqISB0Ruas4uhTCgziH1dMbWvWz0ft5o9f79+uQBDwFXBylPn907ZlR7jmAh3HX\n9UUR6R1JQEQ6iUi32M0wKgIbujRKwmO4SMJfi0gv3ILaDNz82kbcouRfRCkb6gTr4XoW00TkI07O\n/7TERb8dB/4npMz9uC9lXAd87AVzbMX1Rs7E9YhSPR3jjf6Lhwe9ti4DvhCRt3FLDrp4euwCrvec\nkp+7gWdEZAvwGS6MvwFwKW7JwFJV/VuM7S/y6vu7iKzk5Dcth0UK3ojCHOBR3PpHJUqUqqqeEJGr\ncUOJvwT6e+f9a0/vc3EOU4BSG9pU1Q1e9OoNwFjgp17WItyXUy4E/i0iq3A97M64e+op3ILy0PoO\nicj/4uZ/PxGR97xyR1X1Lk9mkYj8FrccZqmIfIl7YdmHu1b+CM8xFNFbNyqYil7fYEflOXCRg8eI\nccG4V6YtbrJ/B+7hvhE3vJQKzCfC4msir6OrhXvIvoJ7mOR5x+fADKBNITr8HPfA+wa3tm43bvF2\nDlEWtBdS107vHIQtGC+iXBWcs1nj6X3As+MPBKwNC5Dvg3ME/8RFdB7EOfc3cR+O9oXI9/LO2ZII\ndaUA43FDbYc8uWN4i68LKxtQx1m4YdDj3vmrVoS91XDf/nwb93WUw7gF1B/i5vmuiOPc+de0Fegc\nRe5cr51jQNeA9JrePbXRO+/f4qI3LyzivNXGRQ1vCzhv+RHkLsT12jd79/g+71y/AdxZmM52VI5D\nvAtpGIZhGAmJzdEZhmEYCY05OsMwDCOhMUdnGIZhJDTm6AzDMIyExhydYRiGkdCYozMMwzASGnN0\nhmEYRkJjjs4wDMNIaMzRGYZhGAmNOTrDMAwjoTFHZxiGYSQ05ugMwzCMhMYcnWEYhpHQ/H8LdFnP\n9EoMsgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21e5cd2f2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve,roc_curve,auc\n",
    "best_param = dict_log['recall']\n",
    "lr = LogisticRegression(penalty=best_param['penalty'],C=best_param['C']).fit(X_train, y_train)\n",
    "lr_predicted = lr.predict(X_test)\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, lr_predicted)\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, lr_predicted)\n",
    "\n",
    "closest_zero = np.argmin(np.abs(thresholds))\n",
    "closest_zero_p = precision[closest_zero]\n",
    "closest_zero_r = recall[closest_zero]\n",
    "plt.figure()\n",
    "plt.xlim([0.0, 1.01])\n",
    "plt.ylim([0.0, 1.01])\n",
    "plt.plot(precision, recall, label='Precision-Recall Curve')\n",
    "plt.plot(closest_zero_p, closest_zero_r, 'o', markersize = 12, fillstyle = 'none', c='r', mew=3)\n",
    "plt.xlabel('Precision', fontsize=16)\n",
    "plt.ylabel('Recall', fontsize=16)\n",
    "plt.axes().set_aspect('equal')\n",
    "plt.show()\n",
    "\n",
    "roc_auc_lr = auc(fpr_lr, tpr_lr)\n",
    "plt.figure()\n",
    "plt.xlim([-0.01, 1.00])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "plt.plot(fpr_lr, tpr_lr, lw=3, label='LogRegr ROC curve (area = {:0.2f})'.format(roc_auc_lr))\n",
    "plt.xlabel('False Positive Rate', fontsize=16)\n",
    "plt.ylabel('True Positive Rate', fontsize=16)\n",
    "plt.title('ROC curve (1-of-10 digits classifier)', fontsize=16)\n",
    "plt.legend(loc='lower right', fontsize=13)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=3, linestyle='--')\n",
    "plt.axes().set_aspect('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes is a simple technique for constructing classifiers: models that assign class labels to problem instances, represented as vectors of feature values, where the class labels are drawn from some finite set. It is not a single algorithm for training such classifiers, but a family of algorithms based on a common principle: all naive Bayes classifiers assume that the value of a particular feature is independent of the value of any other feature, given the class variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classifer Score: \n",
      "\n",
      "0.992556388865\n",
      "Naive Bayes Classifer precision :\n",
      "\n",
      "0.137910447761\n",
      "Naive Bayes Classifer recall: \n",
      "\n",
      "0.626016260163\n",
      "                 Predicted (positive)  Predicted (negative)\n",
      "True (positive)                211792                  1444\n",
      "True (negative)                   138                   231\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB \n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred2 = clf.predict(X_train)\n",
    "\n",
    "# calculate accuracy score\n",
    "clf.score(X_test, y_test)\n",
    "\n",
    "# calculate precision and recall score\n",
    "\n",
    "precision = precision_score(y_train, y_pred2, average='binary')\n",
    "recall = recall_score(y_train, y_pred2, average='binary')\n",
    "\n",
    "print('Naive Bayes Classifer Score: \\n') \n",
    "print(clf.score(X_test, y_test))\n",
    "print('Naive Bayes Classifer precision :\\n')\n",
    "print(precision)\n",
    "print('Naive Bayes Classifer recall: \\n')\n",
    "print(recall)\n",
    "\n",
    "# generate confusion matrix\n",
    "\n",
    "cm = confusion_matrix(y_train,y_pred2)\n",
    "\n",
    "df_cm = pd.DataFrame(cm, index = ['True (positive)', 'True (negative)'])\n",
    "df_cm.columns = ['Predicted (positive)', 'Predicted (negative)']\n",
    "sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "print(df_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision tree learning uses a decision tree (as a predictive model) to go from observations about an item (represented in the branches) to conclusions about the item's target value (represented in the leaves). It is one of the predictive modelling approaches used in statistics, data mining and machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As Decision tree has multiple parameter based on the leafs and depth we can tune our models to specifics so that we can get the maximum score. As we have limited resources we have tuned it on the maximum depth of the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=9)]: Done  30 out of  30 | elapsed:   40.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold,GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(n_splits =3, random_state = 1,shuffle =True)\n",
    "tuning_param = {'max_depth':np.arange(1,11)}\n",
    "\n",
    "clf = GridSearchCV(DecisionTreeClassifier(),param_grid=tuning_param,cv=skf,n_jobs=9,verbose=True,error_score=0,refit='recall')\n",
    "clf.fit(X_train,y_train)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Score Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the best parameter derived from the GredSearchCV we are calculating and comparing the various evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree classifier (max_depth = 5)\n",
      " [[71069    10]\n",
      " [   17   106]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "tree_predicted = clf.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, tree_predicted)\n",
    "\n",
    "print('Decision tree classifier (max_depth = 5)\\n', confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n",
      "Precision: 0.91\n",
      "Recall: 0.86\n",
      "F1: 0.89\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "# Accuracy = TP + TN / (TP + TN + FP + FN)\n",
    "# Precision = TP / (TP + FP)\n",
    "# Recall = TP / (TP + FN)  Also known as sensitivity, or True Positive Rate\n",
    "# F1 = 2 * Precision * Recall / (Precision + Recall) \n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(y_test, tree_predicted)))\n",
    "print('Precision: {:.2f}'.format(precision_score(y_test, tree_predicted)))\n",
    "print('Recall: {:.2f}'.format(recall_score(y_test, tree_predicted)))\n",
    "print('F1: {:.2f}'.format(f1_score(y_test, tree_predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      not 1       1.00      1.00      1.00     71079\n",
      "          1       0.91      0.86      0.89       123\n",
      "\n",
      "avg / total       1.00      1.00      1.00     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Combined report with all above metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, tree_predicted, target_names=['not 1', '1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support vector machines (SVM's, also support vector networks) are supervised learning models with associated learning algorithms that analyze data used for classification and regression analysis. Given a set of training examples, each marked as belonging to one or the other of two categories, an SVM training algorithm builds a model that assigns new examples to one category or the other, making it a non-probabilistic binary linear classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Linear Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  24 out of  24 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "skf = StratifiedKFold(n_splits=3,random_state= 1, shuffle= True)\n",
    "scores = ['accuracy', 'precision', 'recall']\n",
    "\n",
    "tuning_param_svm_lin = [\n",
    "  {'C': [1, 10, 20, 30], 'penalty': ['l1','l2']}\n",
    " ]\n",
    "\n",
    "dict = {}\n",
    " \n",
    "print('Recall')\n",
    "clf = GridSearchCV(LinearSVC(), tuning_param_svm_lin, cv=skf,\n",
    "                       scoring=scores, refit='recall', error_score =0, n_jobs=8, pre_dispatch = 8,verbose = True)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[71079     0]\n",
      " [  114     9]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "svm_predicted_mc = clf.predict(X_test)\n",
    "confusion_mc = confusion_matrix(y_test, svm_predicted_mc)\n",
    "print(confusion_mc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n",
      "Precision: 1.00\n",
      "Recall: 0.07\n",
      "F1: 0.14\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "# Accuracy = TP + TN / (TP + TN + FP + FN)\n",
    "# Precision = TP / (TP + FP)\n",
    "# Recall = TP / (TP + FN)  Also known as sensitivity, or True Positive Rate\n",
    "# F1 = 2 * Precision * Recall / (Precision + Recall) \n",
    "\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(y_test, svm_predicted_mc)))\n",
    "print('Precision: {:.2f}'.format(precision_score(y_test, svm_predicted_mc)))\n",
    "print('Recall: {:.2f}'.format(recall_score(y_test,svm_predicted_mc)))\n",
    "print('F1: {:.2f}'.format(f1_score(y_test, svm_predicted_mc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      not 1       1.00      1.00      1.00     71079\n",
      "          1       1.00      0.07      0.14       123\n",
      "\n",
      "avg / total       1.00      1.00      1.00     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, svm_predicted_mc, target_names=['not 1', '1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Kernel Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to lack of resources we were aunable to tune the kernalised support vector machine. We have run a auto-parameterised model to check the evaluation metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fxf150430\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:220: ConvergenceWarning: Solver terminated early (max_iter=400).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=400, probability=False, random_state=1, shrinking=True,\n",
       "  tol=0.001, verbose=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "skf = StratifiedKFold(n_splits=3,random_state= 1, shuffle= True)\n",
    " \n",
    "print('Recall')\n",
    "clf = SVC(C=1.0, kernel='rbf', gamma='auto', cache_size=200, verbose=True, random_state=1, max_iter=400)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[71079     0]\n",
      " [  116     7]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "svm_predicted_rbf = clf.predict(X_test)\n",
    "confusion_mc = confusion_matrix(y_test, svm_predicted_rbf)\n",
    "print(confusion_mc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n",
      "Precision: 1.00\n",
      "Recall: 0.06\n",
      "F1: 0.11\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "# Accuracy = TP + TN / (TP + TN + FP + FN)\n",
    "# Precision = TP / (TP + FP)\n",
    "# Recall = TP / (TP + FN)  Also known as sensitivity, or True Positive Rate\n",
    "# F1 = 2 * Precision * Recall / (Precision + Recall) \n",
    "\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(y_test, svm_predicted_rbf)))\n",
    "print('Precision: {:.2f}'.format(precision_score(y_test, svm_predicted_rbf)))\n",
    "print('Recall: {:.2f}'.format(recall_score(y_test,svm_predicted_rbf)))\n",
    "print('F1: {:.2f}'.format(f1_score(y_test, svm_predicted_rbf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      not 1       1.00      1.00      1.00     71079\n",
      "          1       1.00      0.06      0.11       123\n",
      "\n",
      "avg / total       1.00      1.00      1.00     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, svm_predicted_rbf, target_names=['not 1', '1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forests or random decision forests are an ensemble learning method for classification, regression and other tasks, that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=9)]: Done  27 out of  27 | elapsed:   43.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 6, 'max_leaf_nodes': 35}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold,GridSearchCV\n",
    "\n",
    "skf = StratifiedKFold(n_splits =3, random_state = 1,shuffle =True)\n",
    "\n",
    "tuning_param = {'max_leaf_nodes':[25,30,35],'max_depth':[4,5,6]}\n",
    "\n",
    "clf = GridSearchCV(RandomForestClassifier(),param_grid=tuning_param,cv=skf,\n",
    "                   n_jobs=9,verbose=True,error_score=0,refit='recall')\n",
    "clf.fit(X_train,y_train)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[71071     8]\n",
      " [   19   104]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "rfc_predicted = clf.predict(X_test)\n",
    "confusion_mc = confusion_matrix(y_test, rfc_predicted)\n",
    "print(confusion_mc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n",
      "Precision: 0.93\n",
      "Recall: 0.85\n",
      "F1: 0.89\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "# Accuracy = TP + TN / (TP + TN + FP + FN)\n",
    "# Precision = TP / (TP + FP)\n",
    "# Recall = TP / (TP + FN)  Also known as sensitivity, or True Positive Rate\n",
    "# F1 = 2 * Precision * Recall / (Precision + Recall) \n",
    "\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(y_test, rfc_predicted)))\n",
    "print('Precision: {:.2f}'.format(precision_score(y_test, rfc_predicted)))\n",
    "print('Recall: {:.2f}'.format(recall_score(y_test,rfc_predicted)))\n",
    "print('F1: {:.2f}'.format(f1_score(y_test, rfc_predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      not 1       1.00      1.00      1.00     71079\n",
      "          1       0.93      0.85      0.89       123\n",
      "\n",
      "avg / total       1.00      1.00      1.00     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, rfc_predicted, target_names=['not 1', '1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In statistics and machine learning, ensemble methods use multiple learning algorithms to obtain better predictive performance than could be obtained from any of the constituent learning algorithms alone. Unlike a statistical ensemble in statistical mechanics, which is usually infinite, a machine learning ensemble consists of only a concrete finite set of alternative models, but typically allows for much more flexible structure to exist among those alternatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard Voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code creates and train a voting classifier in Scikit Learn composed of an ensemble classifier which uses predicted class labels for majority rule voting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)), ('rf', RandomFor...r',\n",
       "  max_iter=-1, probability=False, random_state=42, shrinking=True,\n",
       "  tol=0.001, verbose=False))],\n",
       "         flatten_transform=None, n_jobs=-1, voting='hard', weights=None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_clf = LogisticRegression(random_state=42)\n",
    "rnd_clf = RandomForestClassifier(max_depth= 6, max_leaf_nodes= 30, random_state=42)\n",
    "svm_clf = SVC(random_state=42,kernel='linear')\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)], voting='hard',n_jobs=-1)\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.999199460689\n",
      "LogisticRegression \n",
      " [[71065    14]\n",
      " [   43    80]]\n",
      "RandomForestClassifier 0.999705064464\n",
      "RandomForestClassifier \n",
      " [[71074     5]\n",
      " [   16   107]]\n",
      "SVC 0.998735990562\n",
      "SVC \n",
      " [[71065    14]\n",
      " [   76    47]]\n",
      "VotingClassifier 0.999325861633\n",
      "VotingClassifier \n",
      " [[71070     9]\n",
      " [   39    84]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    print(clf.__class__.__name__,'\\n', confusion)\n",
    "    print(classification_report(y_test, y_pred, target_names=['not 1', '1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soft Voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code creates and train a voting classifier in Scikit Learn composed of an ensemble classifier which predicts the class label based on the argmax of the sums of the predicted probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)), ('rf', RandomFor...stimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False))],\n",
       "         flatten_transform=None, n_jobs=8, voting='soft', weights=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_clf = LogisticRegression(random_state=42)\n",
    "rnd_clf = RandomForestClassifier(max_depth= 6, max_leaf_nodes= 30, random_state=42)\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('rf', rnd_clf)], voting='soft',n_jobs=8)\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.999199460689\n",
      "LogisticRegression \n",
      " [[71065    14]\n",
      " [   43    80]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      not 1       1.00      1.00      1.00     71079\n",
      "          1       0.85      0.65      0.74       123\n",
      "\n",
      "avg / total       1.00      1.00      1.00     71202\n",
      "\n",
      "RandomForestClassifier 0.999705064464\n",
      "RandomForestClassifier \n",
      " [[71074     5]\n",
      " [   16   107]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      not 1       1.00      1.00      1.00     71079\n",
      "          1       0.96      0.87      0.91       123\n",
      "\n",
      "avg / total       1.00      1.00      1.00     71202\n",
      "\n",
      "VotingClassifier 0.999438218028\n",
      "VotingClassifier \n",
      " [[71072     7]\n",
      " [   33    90]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      not 1       1.00      1.00      1.00     71079\n",
      "          1       0.93      0.73      0.82       123\n",
      "\n",
      "avg / total       1.00      1.00      1.00     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "for clf in (log_clf, rnd_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    print(clf.__class__.__name__,'\\n', confusion)\n",
    "    print(classification_report(y_test, y_pred, target_names=['not 1', '1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Bagging classifier is an ensemble meta-estimator that fits base classifiers each on random subsets of the original dataset and then aggregate their individual predictions (either by voting or by averaging) to form a final prediction. Such a meta-estimator can typically be used as a way to reduce the variance of a black-box estimator, by introducing randomization into its construction procedure and then making an ensemble out of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   2 out of   8 | elapsed:  7.6min remaining: 22.7min\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:  7.8min finished\n",
      "[Parallel(n_jobs=8)]: Done   2 out of   8 | elapsed:    3.6s remaining:   10.9s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    6.3s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bag_clf = BaggingClassifier(DecisionTreeClassifier(max_depth = 5, random_state=1), \n",
    "                            n_estimators=500,  bootstrap=True, n_jobs=-1, random_state=1, verbose = True)\n",
    "\n",
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred = bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging classifier\n",
      " [[71071     8]\n",
      " [   16   107]]\n"
     ]
    }
   ],
   "source": [
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print('Bagging classifier\\n', confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n",
      "Precision: 0.93\n",
      "Recall: 0.87\n",
      "F1: 0.90\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "# Accuracy = TP + TN / (TP + TN + FP + FN)\n",
    "# Precision = TP / (TP + FP)\n",
    "# Recall = TP / (TP + FN)  Also known as sensitivity, or True Positive Rate\n",
    "# F1 = 2 * Precision * Recall / (Precision + Recall) \n",
    "\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('Precision: {:.2f}'.format(precision_score(y_test, y_pred)))\n",
    "print('Recall: {:.2f}'.format(recall_score(y_test,y_pred)))\n",
    "print('F1: {:.2f}'.format(f1_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      not 1       1.00      1.00      1.00     71079\n",
      "          1       0.93      0.87      0.90       123\n",
      "\n",
      "avg / total       1.00      1.00      1.00     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Combined report with all above metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=['not 1', '1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When random subsets of the dataset are drawn as random subsets of the samples, then this algorithm is known as Pasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed: 19.3min remaining: 19.3min\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed: 19.4min finished\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    6.8s remaining:    6.8s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    7.6s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bag_clf = BaggingClassifier(DecisionTreeClassifier(max_depth = 5, random_state=1),\n",
    "                            n_estimators=500,  bootstrap=False, n_jobs=-1, random_state=1, verbose = True)\n",
    "\n",
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred = bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging classifier using Pasting\n",
      " [[71067    12]\n",
      " [   17   106]]\n"
     ]
    }
   ],
   "source": [
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print('Bagging classifier using Pasting\\n', confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n",
      "Precision: 0.90\n",
      "Recall: 0.86\n",
      "F1: 0.88\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "# Accuracy = TP + TN / (TP + TN + FP + FN)\n",
    "# Precision = TP / (TP + FP)\n",
    "# Recall = TP / (TP + FN)  Also known as sensitivity, or True Positive Rate\n",
    "# F1 = 2 * Precision * Recall / (Precision + Recall) \n",
    "\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('Precision: {:.2f}'.format(precision_score(y_test, y_pred)))\n",
    "print('Recall: {:.2f}'.format(recall_score(y_test,y_pred)))\n",
    "print('F1: {:.2f}'.format(f1_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      not 1       1.00      1.00      1.00     71079\n",
      "          1       0.90      0.86      0.88       123\n",
      "\n",
      "avg / total       1.00      1.00      1.00     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Combined report with all above metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=['not 1', '1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=6,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "          learning_rate=0.1, n_estimators=200, random_state=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_clf = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=6), n_estimators=200,\n",
    "    algorithm=\"SAMME.R\", learning_rate=0.1, random_state=1)\n",
    "ada_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[71073     6]\n",
      " [   17   106]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = ada_clf.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n",
      "Precision: 0.95\n",
      "Recall: 0.86\n",
      "F1: 0.90\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "# Accuracy = TP + TN / (TP + TN + FP + FN)\n",
    "# Precision = TP / (TP + FP)\n",
    "# Recall = TP / (TP + FN)  Also known as sensitivity, or True Positive Rate\n",
    "# F1 = 2 * Precision * Recall / (Precision + Recall) \n",
    "\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('Precision: {:.2f}'.format(precision_score(y_test, y_pred)))\n",
    "print('Recall: {:.2f}'.format(recall_score(y_test,y_pred)))\n",
    "print('F1: {:.2f}'.format(f1_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      not 1       1.00      1.00      1.00     71079\n",
      "          1       0.95      0.86      0.90       123\n",
      "\n",
      "avg / total       1.00      1.00      1.00     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Combined report with all above metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=['not 1', '1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning parameters the following computationally intensive way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold,GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits =3, random_state = 1,shuffle =True)\n",
    "tuning_param = {'learning_rate':[0.1,0.01,.001,.0001]}\n",
    "\n",
    "clf = GridSearchCV(GradientBoostingClassifier(),param_grid=tuning_param,cv=skf,n_jobs=9,verbose=True,error_score=0,refit='recall')\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting fixed parameters given system performance limitations. Or using clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.5, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=42, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_clf = GradientBoostingClassifier(n_estimators = 100, learning_rate=0.5,random_state=42)\n",
    "gb_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[71061    18]\n",
      " [   85    38]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = gb_clf.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      not 1       1.00      1.00      1.00     71079\n",
      "          1       0.68      0.31      0.42       123\n",
      "\n",
      "avg / total       1.00      1.00      1.00     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Combined report with all above metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=['not 1', '1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on all the models run as part of this project we have the maximum peformance based on our evalution parameter i.e. recall by Random Forest or similar bagging algorithms. Random forest is a special case of bagging classifier where the number of estimators are chosen at random. Bagging classifier is an ensemble meta-estimator that fits base classifiers each on random subsets of the original dataset and then aggregate their individual predictions by averaging to form a final prediction.\n",
    "\n",
    "We have primarily evaluated our models on the ealuation parameter recall which is the primary agenda of this model building project so that we should be able to find the fraud cased maximum accuracy. As per our report we would like to propose **bagging classifier or random forest** as the primary prediction classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Components Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Principal component analysis (PCA) is a statistical procedure that uses an orthogonal transformation to convert a set of observations of possibly correlated variables into a set of values of linearly uncorrelated variables called principal components. The number of principal components is less than or equal to the number of original variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Perform the necessary imports\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Create scaler: scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Create a PCA instance: pca\n",
    "pca = PCA()\n",
    "\n",
    "# Create pipeline: pipeline\n",
    "pipeline = make_pipeline(scaler,pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting PCA for the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEPCAYAAABLIROyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2094934f278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit the pipeline to 'samples'\n",
    "pipeline.fit(X_train)#(pd.merge(X_train,pd.DataFrame(y_train),left_index=True,right_index=True))\n",
    "\n",
    "# Plot the explained variances\n",
    "features = range(pca.n_components_)\n",
    "plt.bar(features, pca.explained_variance_)\n",
    "plt.xlabel('PCA feature')\n",
    "plt.ylabel('variance')\n",
    "plt.xticks(features)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting PCA for test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEPCAYAAABLIROyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nACSpUP8faCsp+8pFdQEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2094cecf048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit the pipeline to 'samples'\n",
    "pipeline.fit(X_test)#(pd.merge(X_train,pd.DataFrame(y_train),left_index=True,right_index=True))\n",
    "\n",
    "# Plot the explained variances\n",
    "features = range(pca.n_components_)\n",
    "plt.bar(features, pca.explained_variance_)\n",
    "plt.xlabel('PCA feature')\n",
    "plt.ylabel('variance')\n",
    "plt.xticks(features)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since 27 of the 29 dimensions are intrinsic we wouldn't save much time by reducing them. If we did reduce them though, this is what it would look like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(213605, 27)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components = 27)\n",
    "pca_Xtrain = pca.fit_transform(X_train)\n",
    "pca_Xtest = pca.fit_transform(X_test)\n",
    "pca_Xtrain.shape"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
